{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Cheatsheets","text":"<p>This site was made with Material for MkDocs based on mkdocs.org and hosted on Github Pages</p>"},{"location":"#set-up-github-pages","title":"Set up Github Pages","text":"<p>The source directory can either be at the root <code>/</code> or a <code>docs/</code> directory.</p> <ol> <li>Create a new repository and setup the local git configuration as usual.</li> <li>Edit the Markdown files as wanted.</li> <li>Create a github workflow under <code>.github/workflows/ci.yml</code> and add the following basic configuration.</li> <li>Now, a push on the <code>main</code> branch will execute this workflow and publish this site.</li> <li>To get the public URL, go to the <code>settings</code> tab and under \"Code and automation\" section of the sidebar click on Pages.</li> <li>Under \"Build and deployment\", under \"Source\", select Deploy from a branch.</li> <li>Under \"Build and deployment\", under Branch, select the dropdown menu and select the <code>gh-pages</code> branch and click on Save.</li> <li>Optionally, use the folder dropdown menu to select a folder for your publishing source. (e.g. <code>/</code>or <code>docs/</code>)</li> <li>Now the site should be available on : <code>https://&lt;github-account&gt;.github.io/&lt;your-repo&gt;/</code> or go to the Actions tab, under ci click on the workflow (with a green check) and then click on deploy (with a green check) and then expand the Run mkdocs gh-deploy --force step to see the public URL.</li> </ol>"},{"location":"#workflow-configuration","title":"Workflow configuration","text":"<pre><code>name: ci \non:\n  push:\n    branches:\n      - master \n      - main\npermissions:\n  contents: write\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: 3.x\n      - uses: actions/cache@v2\n        with:\n          key: ${{ github.ref }}\n          path: .cache\n      - run: pip install mkdocs-material\n      - run: pip install pillow cairosvg\n      - run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"python/best_practices/","title":"Best Practices for Python Code (PEP 8 Guidelines)","text":"<p>Note</p> <p>When writing Python code, it's important to follow consistent coding standards to ensure readability and maintainability of your codebase. Python's official style guide, PEP 8, provides guidelines for writing clean and Pythonic code. </p> <p>Some modules can help you write or format your code according to thes guidelines:</p> <ul> <li><code>Flake8</code> : lint code</li> <li><code>Black</code> : format code</li> <li><code>Isort</code> : format only imports</li> <li><code>Mypy</code> : check typing</li> </ul> <p>Here are some best practices to keep in mind.</p>"},{"location":"python/best_practices/#virtual-environments","title":"Virtual Environments","text":"<p>Recommended to isolate project. It lets you have a stable, reproducible, and portable environment. Benefits of using virtual environments include :</p> <ul> <li>Avoid system pollution</li> <li>Avoid Dependency Conflicts</li> <li>Minimize reproducibility issues</li> <li>Avoid installation privilege lockouts</li> </ul> <p>There are many ways of creating a virtual environment (see the Environment section for more details)  The most common one is by using <code>venv</code> module.</p> <p><pre><code># go under the project directory\ncd &lt;project_directory&gt;\n\n# create a virtual environment usually named env, venv or .venv\npython -m venv .venv\n</code></pre> It creates a <code>.venv</code> folder at the root of your project.</p> <p>Note</p> <p>The <code>.venv</code> folder stores all the packages you will install, hence increasing the byte size of the project. If your using a <code>git</code> repository to store your project, make sure to create or update the <code>.gitignore</code> file to include the <code>.venv</code> folder. </p> <p>Then activate the environment. it will add a <code>(.venv)</code> extension at the beginning of your prompt in the terminal</p> <pre><code># windows\n.\\.venv\\Scripts\\Activate.ps1\n\n# linux\n./.venv/bin/activate\n</code></pre> <p>When you install package using <code>pip</code>, it will use the <code>pip</code> program from the <code>.venv</code> folder. After you're done with installing packages, run the following command to make a snapshot of your depencies.</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>It will create a <code>requirements.txt</code> file containing all your installed packages. That way, when you need to clone the project to another computer from a <code>git</code> repository, install the dependencies with</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"python/best_practices/#indentation","title":"Indentation","text":"<ul> <li>Use 4 spaces per indentation level.</li> <li>Avoid tabs (Change in your IDE Settings if needed), and never mix tabs and spaces.</li> </ul> <p>Bad: <pre><code>def my_function():\n  print(\"Indentation is inconsistent.\")         # 2 spaces\n\ndef my_function():\n        print(\"Indentation is inconsistent.\")   # 8 spaces\n</code></pre></p> <p>Good: <pre><code>def my_function():\n    print(\"Indentation is inconsistent.\")       # 4 spaces\n</code></pre></p>"},{"location":"python/best_practices/#maximum-line-length","title":"Maximum Line Length","text":"<ul> <li>Limit all lines to a maximum of 79 characters for code and comments.</li> <li>Break lines longer than 79 characters into readable, logical continuation lines.</li> </ul> <p>Bad: <pre><code>my_long_variable_name = some_function_with_a_long_name(argument1, argument2, argument3, argument4)\n</code></pre></p> <p>Good: <pre><code>my_long_variable_name = some_function_with_a_long_name(\n    argument1, argument2, argument3, argument4\n)\n</code></pre></p>"},{"location":"python/best_practices/#imports","title":"Imports","text":"<ul> <li>Imports should be on separate lines.</li> <li>Imports should usually be grouped in the following order: <ul> <li>standard library.</li> <li>third-party imports.</li> <li>local application/library specific.</li> </ul> </li> <li>Avoid wildcard imports (<code>from module import *</code>), it makes it unclear which names are present in the namespace.</li> </ul> <p>Bad: <pre><code>import os, sys\nimport user_lib\nimport pandas as pd\nfrom math import *\n</code></pre></p> <p>Good: <pre><code>import os                   # standard\nimport sys\nfrom math import sqrt\n\nimport pandas as pd         # 3rd party\n\nimport user_lib             # user\n</code></pre></p>"},{"location":"python/best_practices/#whitespace-in-expressions-and-statements","title":"Whitespace in Expressions and Statements","text":"<p>Avoid extraneous whitespace in the following situations:</p> <ul> <li>Immediately inside parentheses, brackets, or braces.</li> <li>Between a trailing comma and a following close parenthesis.</li> </ul> <p>Bad: <pre><code>print( value1 , value2 )\nlist1 = [ 1,2 , 3 ,4]\ndict1 = { \"key1\" : val , \"key2\" : 3 }\n</code></pre></p> <p>Good: <pre><code>print(value1, value2)\nlist1 = [1, 2, 3 , 4]\ndict1 = {\"key1\": val , \"key2\": 3}\n</code></pre></p>"},{"location":"python/best_practices/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Use descriptive names for variables, functions, and modules.</li> <li>Use <code>snake_case</code> for function and variable names.</li> <li>Use <code>CamelCase</code> for class names.</li> <li>Use <code>UPPER_CASE</code> for constants names.</li> </ul> <p>Bad: <pre><code>a = \"This is not a good variable name\"\nconstante = 3\n\ndef BadFunctionName():\n    pass\n\nclass bad_class_name():\n    pass\n</code></pre></p> <p>Good: <pre><code>meaningful_name = \"This is a good variable name\"\nCONSTANTE = 3\n\ndef good_function_name():\n    pass\n\nclass GoodClassName():\n    pass\n</code></pre></p>"},{"location":"python/best_practices/#comments-and-documentation","title":"Comments and Documentation","text":"<ul> <li>Use comments sparingly but effectively to explain complex parts of your code.</li> <li>Write docstrings for all public modules, functions, classes, and methods.</li> <li>Add a space between the <code>#</code> sign and the comment</li> </ul> <p>Bad: <pre><code>#bad comment\n\n# x += 1  # Increment x\n\ndef function(a):\n    a += 1\n    return a\n</code></pre></p> <p>Good: <pre><code># good comment\nx += 1 # Increment x\n\ndef function(a):\n    \"\"\"This function increments a\"\"\"\n    a += 1\n    return a\n</code></pre></p>"},{"location":"python/best_practices/#function-and-method-arguments","title":"Function and Method Arguments","text":"<ul> <li>Always put positional arguments before keyword arguments.</li> <li>Don't use mutable objects as default values for function or method arguments.</li> </ul> <p>Bad: <pre><code>def my_function(x=[])  # Default value is a mutable list\n</code></pre></p> <p>Good: <pre><code>def my_function(x, y, z=None):  # z is a keyword argument with a default value of None\n</code></pre></p>"},{"location":"python/best_practices/#exception-handling","title":"Exception Handling","text":"<ul> <li>Specific exceptions should be caught instead of using a generic <code>except</code> clause.</li> <li>Avoid using bare <code>except:</code> clauses, specify the exception(s) you expect.</li> </ul> <p>Bad: <pre><code>try:\n    # some code that might raise an exception\nexcept:\n    # handle the exception\n</code></pre></p> <p>Good: <pre><code>try:\n    # some code that might raise an exception\nexcept ValueError:\n    # handle the specific ValueError exception\n</code></pre></p>"},{"location":"python/best_practices/#development-best-practices","title":"Development Best Practices","text":"<ul> <li>Keep your code DRY (Don't Repeat Yourself) and follow the principle of modularity.</li> <li>Write unit tests for your code to ensure its correctness and ease of maintenance.</li> <li>Use version control systems like Git to track changes and collaborate effectively.</li> <li>Use TDD (Test Driven Developpement). Write test before you code the function.</li> <li>Use Design Patterns. You are not the first developer, the most common patterns are already documented.</li> </ul>"},{"location":"python/best_practices/#linting-and-formatting-your-code","title":"Linting and Formatting Your Code","text":""},{"location":"python/environment/","title":"Environment","text":""},{"location":"python/environment/#install-packages-with-pip","title":"Install Packages with <code>pip</code>","text":"<pre><code>python -m pip install --upgrade pip             # upgrade pip\n\npip install &lt;package1&gt; &lt;package2&gt; ...           # install a package\n\npip list                                        # print installed packages in a pretty fashion \npip freeze                                      # print installed packages readable for the requirements.txt file\npip freeze &gt; requirements.txt                   # write installed packages to the file requirements.txt\npython -m site                                  # print the site-packages directories on the drive\npip show &lt;package_name&gt;                         # show package_name info\n\npip install requests==2.1.0                     # install a package with specific version\npip install \"requests&gt;2.4.0,&lt;2.6.0\"             # install a package within versions\npip install -r requirements.txt                 # install a package lister par pip freeze dans requirements.txt\n</code></pre>"},{"location":"python/environment/#virtual-environment","title":"Virtual Environment","text":"<pre><code>pip install venv                                # install venv package\npython -m venv &lt;env_name&gt;                       # create a virtual environnement \"env_name\"\nsource env/Scripts/activate                     # activate the virtual environment (env/Scripts/activate.bat Windows)\ndeactivate                                      # deactivate the current virtual environment\n</code></pre>"},{"location":"python/environment/#pipenv","title":"Pipenv","text":"<p>Useful to deal with dependencies</p> <p>Install pipenv <pre><code>pip install pipenv --user\n</code></pre></p> <p>Create a <code>.venv</code> folder (or put <code>PIPENV_VENV_IN_PROJECT=1</code> into a <code>.env</code> file that pipenv will load when invoke) <pre><code>mkdir .venv                                     # if .venv not created, it installs .venv in ~/.venv (or export PIPENV_VENV_IN_PROJECT=1)\npipenv install [-r requirements.txt]            # if requirements.txt is not provided, install from Pipfile\n\npipenv install --python=/path/to/python         # use a specific interpreter/version\n</code></pre></p> <p>Activate venv <pre><code>pipenv shell\n</code></pre></p> <p>Install in prod or dev environment  place the package in the default or dev + defaults section of the Pipfile and Pipfile.lock <pre><code>pipenv install &lt;package&gt; [--dev]\n</code></pre> Generate a <code>requirements.txt</code> file (only default, with dev or only dev) <pre><code>pipenv lock -r [--dev | --dev-only] &gt; requirements.txt\n</code></pre></p> <p>Check for vulnerabilities in dependencies <pre><code>pipenv check\n</code></pre></p>"},{"location":"python/environment/#environment-variables","title":"Environment Variables","text":"<pre><code># Linux\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/src\n\n# Command Prompt\nset PYTHONPATH=%PYTHONPATH%;%CWD%\\src\n\n# Powershell\n$env:PYTHONPATH=\"$env:PYTHONPATH;${PWD}\\src\"\n</code></pre>"},{"location":"python/executable/","title":"Create an Executable","text":""},{"location":"python/executable/#install-with-python-2","title":"Install with python 2","text":"<pre><code>sudo apt-get install python-dev\npip install cx_Freeze\n</code></pre>"},{"location":"python/executable/#install-with-python-3","title":"Install with python 3","text":"<ul> <li>Download <code>cx_Freeze</code> library et extract it</li> <li>in <code>setup.py</code>, replace the following line:</li> </ul> <pre><code>if not vars.get(\"Py_ENABLE_SHARED\", 0):\n</code></pre> <p>with:</p> <pre><code>if True:\n</code></pre> <ul> <li>Compile <pre><code>setup.py build\nsetup.py install\n</code></pre></li> </ul>"},{"location":"python/executable/#setup","title":"Setup","text":"<p>The name must be <code>setup.py</code></p> <pre><code>from cx_Freeze import setup, Executable\n\n# Call the setup function\nsetup(\n    name = \"program_name\",\n    version = \"1\",\n    description = \"Program description\",\n    executables = [Executable(\"script_name.py\")],\n)\n</code></pre>"},{"location":"python/executable/#build","title":"Build","text":"<pre><code>python setup.py build\n</code></pre>"},{"location":"python/installation/","title":"Installation","text":"<p>Upgrade <code>python</code> directly from the Download page</p> <p>Verify installation with the following command</p> <pre><code>python --version\n\n## returns\n# Python 3.X.X\n</code></pre>"},{"location":"python/logging/","title":"Logging Events","text":""},{"location":"python/logging/#purpose-of-logging","title":"Purpose of logging","text":"<p>There are 2 main goals in logging :</p> <ul> <li>Diagnosis : records events related to the operations of an application</li> <li>Audit : records events for business analysis.</li> </ul> <p>The Python <code>logging</code> library is a convenient way to do so. It has a number of advantages over printing :</p> <ul> <li>Easy to see where and when (even what line no.) a logging call is being made from.</li> <li>You can log to <code>files</code>, <code>sockets</code>, pretty much anything, all at the same time.</li> <li>You can differentiate your logging based on severity levels.</li> <li>If your project is meant to be imported by other python tools, it's bad practice for your package to print things to stdout, since the user likely won't know where the print messages are coming from. With logging, users of your package can choose whether they want to propogate logging messages from your tool or not.</li> </ul> <p>For more details about logging, please see basic and advanced tutorials here</p>"},{"location":"python/logging/#severity-levels","title":"Severity Levels","text":"Level When it\u2019s used <code>DEBUG</code> Detailed information, typically of interest only when diagnosing problems. <code>INFO</code> Confirmation that things are working as expected. <code>WARNING</code> An indication that something unexpected happened, or indicative of some problem in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected. <code>ERROR</code> Due to a more serious problem, the software has not been able to perform some function. <code>CRITICAL</code> A serious error, indicating that the program itself may be unable to continue running."},{"location":"python/logging/#logger-configuration","title":"Logger configuration","text":"<p>There are 3 methods to configure a logger in Python :</p> <ul> <li><code>INI</code> file :<ul> <li>Pros : change the config during the execution.</li> <li>Cons : less control.</li> </ul> </li> <li>Using a Python <code>Dict</code> or <code>JSON</code> formatted file :<ul> <li>Pros : change the config during the execution </li> <li>Cons : less control than with code.</li> </ul> </li> <li>Directly with code : <ul> <li>Pros : complete control on the configuration.</li> <li>Cons : need to change source code.</li> </ul> </li> </ul>"},{"location":"python/logging/#examples","title":"Examples","text":""},{"location":"python/logging/#ini-file","title":"INI File","text":"config.ini<pre><code>[loggers]\nkeys=root\n\n[handlers]\nkeys=stream_handler\n\n[formatters]\nkeys=formatter\n\n[logger_root]\nlevel=DEBUG\nhandlers=stream_handler\n\n[handler_stream_handler]\nclass=StreamHandler\nlevel=DEBUG\nformatter=formatter\nargs=(sys.stderr,)\n\n[formatter_formatter]\nformat=%(asctime)s %(name)-12s %(levelname)-8s %(message)s\n</code></pre> <p>Then use <code>logging.config.fileConfig()</code> in the code:</p> app.py<pre><code>import logging\nfrom logging.config import fileConfig\n\nfileConfig('config.ini')\nlogger = logging.getLogger()\nlogger.debug('often makes a very good meal of %s', 'visiting tourists')\n</code></pre>"},{"location":"python/logging/#json","title":"JSON","text":"app.py<pre><code>import logging\nfrom logging.config import dictConfig\n\nlogging_config = dict(\n    version = 1,\n    formatters = {\n        'f': {'format':\n              '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'}\n        },\n    handlers = {\n        'h': {'class': 'logging.StreamHandler',\n              'formatter': 'f',\n              'level': logging.DEBUG}\n        },\n    root = {\n        'handlers': ['h'],\n        'level': logging.DEBUG,\n        },\n)\n\ndictConfig(logging_config)\n\nlogger = logging.getLogger()\nlogger.debug('often makes a very good meal of %s', 'visiting tourists')\n</code></pre>"},{"location":"python/logging/#code","title":"Code","text":"app.py<pre><code>import logging\n\nlogger = logging.getLogger()\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)\nlogger.setLevel(logging.DEBUG)\n\nlogger.debug('often makes a very good meal of %s', 'visiting tourists')\n</code></pre> <p>For simple configuration needs, we can use the <code>basicConfig()</code> function.</p> app.py<pre><code>import logging\n\nlogging.basicConfig(\n    encoding=\"utf-8\",\n    level=INFO,\n    format=\"[%(asctime)s] %(levelname)-7s %(module)-15s %(lineno)-5d : %(message)s\",\n    datefmt=\"%Y-%m-%d %H:%M:%S\",\n    handlers=[\n        RotatingFileHandler(            # saves logs to a new file once the size of the current logfile reach the maxBytes size\n            filename,\n            maxBytes=2 * 1024 * 1024,\n            backupCount=5,\n        ),\n        logging.StreamHandler(),        # to display logs in the standard output (terminal)\n    ],\n)\n\nlogging.info(\"Opening file...\")\n...\nlogging.error(\"File doesn't exists\")\n</code></pre>"},{"location":"python/logging/#log-records-format","title":"Log records format","text":"<p>For the above format</p> <pre><code>\"[%(asctime)s] %(levelname)-7s %(module)-15s %(lineno)-5d : %(message)s\" \n</code></pre> <p>The output file might look like this :</p> app.log<pre><code>[2023-12-06 11:19:53] DEBUG   db              25    : Creating database connection object...\n[2023-12-06 11:19:53] DEBUG   db              37    : Connection object created successfully.\n[2023-12-06 11:19:53] INFO    utils           84    : Database is up\n[2023-12-06 11:19:53] DEBUG   db              42    : Database connection closed.\n</code></pre> <p>The log format can be customize through LogRecords attributes to get a very descriptive insight from the log.</p>"},{"location":"python/project/","title":"Project Structure","text":""},{"location":"python/project/#from-hitchhikers","title":"From Hitchhiker's","text":"<pre><code>README.rst\nLICENSE\nsetup.py\nrequirements.txt\nsample/\n    __init__.py\n    core.py\n    helpers.py\ndocs/\n    conf.py\n    index.rst\ntests/\n    test_basic.py\n    test_advanced.py\n</code></pre>"},{"location":"python/project/#from-pytest-doc","title":"From Pytest doc","text":"<pre><code>src/\n    mypkg/\n        __init__.py\n        app.py\n        view.py\ntests/\n    test_app.py\n    test_view.py\n    ...\n</code></pre> <p>Avoid using <code>__init__.py</code> in test folder</p> <pre><code>new_project\n\u251c\u2500\u2500 antigravity\n\u2502   \u251c\u2500\u2500 __init__.py         # make it a package\n\u2502   \u2514\u2500\u2500 antigravity.py\n\u2514\u2500\u2500 test\n    \u251c\u2500\u2500 __init__.py         # also make test a package\n    \u2514\u2500\u2500 test_antigravity.py\n\n# deal with relative path \nimport os\nFILE = os.path.realpath(os.path.join(os.path.dirname(__file__), '..','data', 'api_keys.txt'))\n</code></pre>"},{"location":"python/project/#main-structure","title":"Main Structure","text":"<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*- \n#----------------------------------------------------------------------------\n# Created By  : name_of_the_creator\n# Created Date: date/month/time ..etc\n# version ='1.0'\n# ---------------------------------------------------------------------------\n\"\"\" Extraction of all relevant fields in the Datatourisme DB\n\nThe script extracts the programmated stream from the Datatourisme website and \nchecks for all updated POIs before transforming it and loading it into the \nAgoraa MySQL DB. \n\nUsage: \n    $ python datatourisme.py\n\"\"\"\n\n__author__ = \"Philippe Vaudin\"\n__copyright__ = \"Copyright 2007, The Cogent Project\"\n__credits__ = [\"Rob Knight\", \"Peter Maxwell\"]\n__license__ = \"GPL\"\n__version__ = \"1.0.1\"\n__date__ = 14/03/2023\n__maintainer__ = \"Philippe Vaudin\"\n__email__ = \"philippe@agoraa.fr\"\n__status__ = \"Production\"   # ou 'Development' ou 'Prototype'\n\n\nimport os           # standard library\nimport sys\n\nimport requests     # 3rd party packages\n\nimport mypackage    # local source\n\n\nprint(\"This is my file to demonstrate best practices.\")\n\n\ndef process_data(data):\n    print(\"Beginning data processing...\")\n    modified_data = data + \" that has been modified\"\n    sleep(3)\n    print(\"Data processing finished.\")\n    return modified_data\n\n\ndef read_data_from_web():\n    print(\"Reading data from the Web\")\n    data = \"Data from the web\"\n    return data\n\n\ndef write_data_to_database(data):\n    print(\"Writing data to a database\")\n    print(data)\n\n\ndef main():\n    data = read_data_from_web()\n    modified_data = process_data(data)\n    write_data_to_database(modified_data)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"python/project/#create-packages","title":"Create Packages","text":"<p>All directory with an <code>__init__.py</code> file is considered as a package.</p> <p>Structure of a python package (in the same directory as the said program): <pre><code>- program_name.py\n- package_name/\n    - __init__.py\n    - module1.py\n    - module2.py\n    -...\n</code></pre></p>"},{"location":"python/python/","title":"Python","text":""},{"location":"python/python/#create-an-executable","title":"Create an Executable","text":"<p>Install with python 2 <pre><code>sudo apt-get install python-dev\npip install cx_Freeze\n</code></pre></p> <p>Install with python 3</p> <ul> <li>Download <code>cx_Freeze</code> library et extract</li> <li>in <code>setup.py</code>, replace the following line:</li> </ul> <pre><code>if not vars.get(\"Py_ENABLE_SHARED\", 0):\n</code></pre> <p>with:</p> <pre><code>if True:\n</code></pre> <ul> <li>Compile <pre><code>setup.py build\nsetup.py install\n</code></pre></li> </ul> <p>Program</p> <p>The name must be <code>setup.py</code></p> <pre><code>from cx_Freeze import setup, Executable\n\n# Call the setup function\nsetup(\n    name = \"program_name\",\n    version = \"1\",\n    description = \"Program description\",\n    executables = [Executable(\"script_name.py\")],\n)\n</code></pre> <p>Build</p> <pre><code>python setup.py build\n</code></pre>"},{"location":"python/python/#project-structure","title":"Project Structure","text":"<pre><code># from Hitchhiker's\n\nREADME.rst\nLICENSE\nsetup.py\nrequirements.txt\nsample/__init__.py\nsample/core.py\nsample/helpers.py\ndocs/conf.py\ndocs/index.rst\ntests/test_basic.py\ntests/test_advanced.py\n\n\n# From Pytest doc\n\nsrc/\n    mypkg/\n        __init__.py\n        app.py\n        view.py\ntests/\n    test_app.py\n    test_view.py\n    ...\n\n\n# Avoid using __init__.py in test folder\n\nnew_project\n\u251c\u2500\u2500 antigravity\n\u2502   \u251c\u2500\u2500 __init__.py         # make it a package\n\u2502   \u2514\u2500\u2500 antigravity.py\n\u2514\u2500\u2500 test\n    \u251c\u2500\u2500 __init__.py         # also make test a package\n    \u2514\u2500\u2500 test_antigravity.py\n\n# deal with relative path \nimport os\nFILE = os.path.realpath(os.path.join(os.path.dirname(__file__), '..','data', 'api_keys.txt'))\n</code></pre> <p>Main Structure</p> <pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*- \n#----------------------------------------------------------------------------\n# Created By  : name_of_the_creator\n# Created Date: date/month/time ..etc\n# version ='1.0'\n# ---------------------------------------------------------------------------\n\"\"\" Extraction of all relevant fields in the Datatourisme DB\n\nThe script extracts the programmated stream from the Datatourisme website and \nchecks for all updated POIs before transforming it and loading it into the \nAgoraa MySQL DB. \n\nUsage: \n    $ python datatourisme.py\n\"\"\"\n\n__author__ = \"Philippe Vaudin\"\n__copyright__ = \"Copyright 2007, The Cogent Project\"\n__credits__ = [\"Rob Knight\", \"Peter Maxwell\"]\n__license__ = \"GPL\"\n__version__ = \"1.0.1\"\n__date__ = 14/03/2023\n__maintainer__ = \"Philippe Vaudin\"\n__email__ = \"philippe@agoraa.fr\"\n__status__ = \"Production\"   # ou 'Development' ou 'Prototype'\n\n\nimport os           # standard library\nimport sys\n\nimport requests     # 3rd party packages\n\nimport mypackage    # local source\n\n\nprint(\"This is my file to demonstrate best practices.\")\n\n\ndef process_data(data):\n    print(\"Beginning data processing...\")\n    modified_data = data + \" that has been modified\"\n    sleep(3)\n    print(\"Data processing finished.\")\n    return modified_data\n\n\ndef read_data_from_web():\n    print(\"Reading data from the Web\")\n    data = \"Data from the web\"\n    return data\n\n\ndef write_data_to_database(data):\n    print(\"Writing data to a database\")\n    print(data)\n\n\ndef main():\n    data = read_data_from_web()\n    modified_data = process_data(data)\n    write_data_to_database(modified_data)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"python/python/#create-packages","title":"Create Packages","text":"<p>All directory with an <code>__init__.py</code> file is considered as a package.</p> <p>Structure of a python package (in the same directory as the said program): <pre><code>- nom_programme.py\n- nom_package/\n    - __init__.py\n    - nom_module1.py\n    - nom_module2.py\n    -...\n</code></pre></p>"},{"location":"python/python/#python-basics","title":"Python Basics","text":""},{"location":"python/python/#operators","title":"Operators","text":"Symbole Op\u00e9ration Exemple + Addition 6+4 returns 10 - Substraction 6-4 returns 2 * Multiplication 6*4 returns 24 / Division 6/4 returns 1.5 // Integer division 6.0//4 returns 1 ** Power 6**4 returns 1296 % Modulo 6 % 4 returns 2"},{"location":"python/python/#assignation","title":"Assignation","text":"Symbole Op\u00e9ration += Addition -= Substraction *= Multiplication /= Division //= Integer division **= Power %= Modulo"},{"location":"python/python/#comparison","title":"Comparison","text":"Expression Exemple Signification &lt; x &lt; y Est-ce que x est strictement inf\u00e9rieur \u00e0 y ? &lt;= x &lt;= y Est-ce que x inf\u00e9rieur ou \u00e9gal \u00e0 y ? &gt; x &gt; y Est-ce que x est strictement sup\u00e9rieur \u00e0 y ? &gt;= x &gt;= y Est-ce que x est sup\u00e9rieur ou \u00e9gal \u00e0 y ? == x == y Est-ce que x est \u00e9gal \u00e0 y ? != x != y Est-ce que x est diff\u00e9rent de y ?"},{"location":"python/python/#logical-comparison","title":"Logical Comparison","text":"Op\u00e9rateur Exemple Signification and P and Q Est-ce que P et Q sont toutes deux vraie ? or P or Q Est-ce que au moins une des expressions parmi P et Q est vraie ? not not P La n\u00e9gation de l'expression P"},{"location":"python/python/#membership","title":"Membership","text":"Expression Exemple Signification in \"France\" in extrait return true if France is in extrait not in \"France\" not in extrait return true if France is not in extrait"},{"location":"python/python/#variable-names-scope","title":"Variable Names Scope","text":"<ul> <li> <p><code>variable_name</code> : normal variable</p> </li> <li> <p><code>_single_leading_underscore</code> : weak module internal use indicator.</p> <p>E.g. : <code>from M import *</code> does not import objects whose name starts with an underscore.</p> </li> <li> <p><code>single_trailing_underscore_</code>: used by convention to avoid conflicts with Python keyword.</p> <p>E.g.: Tkinter.Toplevel(master, class_='ClassName')</p> </li> <li> <p><code>__double_leading_underscore</code>: when naming a class attribute, invokes <code>name mangling</code>  (inside class FooBar, __boo becomes _FooBar__boo; see below).</p> </li> <li> <p><code>__double_leading_and_trailing_underscore__</code>: \u201cmagic\u201d objects or attributes that live in user-controlled namespaces. </p> <p>E.g. <code>__init__</code>, <code>__import__</code> or <code>__file__</code>. Never invent such names; only use them as documented.</p> </li> </ul>"},{"location":"python/python/#control-structures","title":"Control Structures","text":"<pre><code># normal control\nif condition:\n    statment\nelif condition:\n    statment\nelse:\n    statment\n\n# conditionnal assignment \nredouble = True if moyenne &lt; 10 else False\n</code></pre>"},{"location":"python/python/#loops","title":"Loops","text":"<pre><code>while condition:\n    statment\n\nfor item in sequence:                           # sequence can be range, list/dict/tuple\n    statment\n\nfor item in range(start, end, step):            # sequence can be a range\n    statment                                    # 'end' is exclusive, step not necessary (1 by default)\n                                                # range(n) -&gt; goes from 0 to n-1\n\nma_liste = [i**2 for i in range(10)]            # list comprehension (can be used for generator with \"()\" instead of \"[]\")\nliste_pairs = [\"pair\" if n%2 == 0 else \"impair\" for n in liste_nombres]\n\nfor index, element in enumerate(sequence):      # enumerate returns item and index of item\n\nfor item1, item2 in zip(seq1, seq2, ...)        # zip iterates on multiple sequences at a time\n</code></pre>"},{"location":"python/python/#types","title":"Types","text":"<pre><code>type(var)                                       # type of variable var\nid(a)                                           # This is the address of the object in memory \n</code></pre>"},{"location":"python/python/#string","title":"String","text":"<pre><code>s.split(sep,maxsplit)                           # sep default is space ans maxsplit is the number of splits to do. default is -1 which splits all the items.\n'-'.join([la,bas])                              # returns \"la-bas\"\ns.strip()                                       # remove all right and left spaces from s\ns.strip(\"()\")                                   # remove all ( and ) from s on right and left\ns.lower()\ns.upper()\ns.swapcase()\ns.count('c')                                    # count number of 'c' character in s\nsorted(s, reverse=True)                         # permet de trier les caract\u00e8res de s\n</code></pre>"},{"location":"python/python/#format-string","title":"Format-String","text":"<pre><code>print(f\"{DEBUG = }\")                # print DEBUG = False \n\nf'{nombre : &gt;+20_.4f} {nombre2 : &gt;+20_.4f}')\n3.1415926       {:.2f}  3.14        Format float 2 decimal places\n3.1415926       {:+.2f} +3.14       Format float 2 decimal places with sign\n-1              {:+.2f} -1.00       Format float 2 decimal places with sign\n2.71828         {:.0f}  3           Format float with no decimal places\n4               {:0&gt;2d} 04          Pad number with zeros (left padding, width 2)\n4               {:x&lt;4d} 4xxx        Pad number with x\u2019s (right padding, width 4)\n10              {:x&lt;4d} 10xx        Pad number with x\u2019s (right padding, width 4)\n1000000         {:,}    1,000,000   Number format with comma separator\n0.35            {:.2%}  35.00%      Format percentage\n1000000000      {:.2e}  1.00e+09    Exponent notation\n11              {:11d}  11          Right-aligned (default, width 10)\n11              {:&lt;11d} 11          Left-aligned (width 10)\n11              {:^11d} 11          Center aligned (width 10)\n</code></pre> <p><code>[[fill]align][sign][#][0][minimumwidth][.precision][type]</code></p> <p><pre><code># align and fill\n'&lt;' - left-aligned within the available space (This is the default.)\n'&gt;' - right-aligned within the available space.\n'^' - centered within the available space.\n'=' - (for numeric types) Forces the padding to be placed after the sign (if any)\n      but before the digits.  This is used for printing fields\n      in the form '+000000120'.\n</code></pre> <pre><code># sign option just for numeric types\n'+'  - sign should be used for both positive and negative numbers\n'-'  - sign should be used only for negative numbers (default)\n' '  - leading space should be used on positive numbers\n</code></pre> <pre><code>'b' - Binary. Outputs the number in base 2.\n'c' - Character. Converts the integer to the corresponding Unicode character before printing.\n'd' - Decimal Integer. Outputs the number in base 10.\n'o' - Octal format. Outputs the number in base 8.\n'x' - Hex format. Outputs the number in base 16, using lower-case letters for the digits above 9.\n'X' - Hex format. Outputs the number in base 16, using upper-case letters for the digits above 9.\n'n' - Number. This is the same as 'd', with current locale setting to insert the appropriate number separator characters.\n'' (None) - the same as 'd'\n</code></pre> <pre><code>'e' - Exponent notation.\n'E' - Exponent notation. Same as 'e' except it converts the number to uppercase.\n'f' - Fixed point. Displays the number as a fixed-point number.\n'F' - Fixed point. Same as 'f' except it converts the number to uppercase.\n'g' - General format. fixed-point number, unless the number is too large, in which case it switches to 'e'\n'G' - General format. Same as 'g' except switches to 'E' if the number gets to large.\n'n' - Number. This is the same as 'g', with current locale setting to insert the appropriate number separator characters.\n'%' - Percentage. Multiplies the number by 100 and displays in fixed ('f') format, followed by a percent sign.\n'' (None) - similar to 'g', except that it prints at least one digit after the decimal point.\n</code></pre></p>"},{"location":"python/python/#regex","title":"Regex","text":"<pre><code>import re\n</code></pre>"},{"location":"python/python/#lists","title":"Lists []","text":"<pre><code># processing\nmy_list.pop(1)                                  # remove item at index 1\nmy_list.remove(value)                           # remove first occurence of value\nmy_list.append(x)                               # append x to the end of the list\nmy_list.insert(1,x)                             # insert x at the index 1 in the list\nmy_list.extend(my_other_list)                   # extend ma_liste with my_other_list\nmy_list.sort()                                  # sort list (reversed=True for reverse order)\nsorted(my_list)                                 # m\u00eame effet que pour sort() mais s'utilise aussi sur les string\nmy_list.reverse()                               # (In-place) reverse all element of my_list\nmy_list.clear()                                 # remove all item from list\nmy_list.index(value)                            # return first index of value\nmy_list.copy()                                  # copy of my_list\n\n# slicing\nmy_list[start:end:step]                         # end is exclusive, step not necessary (1 by default) \nmy_list[0]                                      # first element\nmy_list[-1]                                     # last element\nmy_list[0:2:-1]                                 # \nmy_list[::-1]                                   # reverted order\nmy_list[...,0]                                  # [:, :, :, 0], [\u2026, 0] and [Ellipsis, 0] are equivalent\n</code></pre>"},{"location":"python/python/#tuples","title":"Tuples ()","text":"<pre><code>un_tuple = \"Bonjour\", -1, 133\nx, y, z = un_tuple                              # Tuple assignment (number of variable = number of item in tuple)\na, b = b, a                                     # value swapping instead of tmp variable\n</code></pre>"},{"location":"python/python/#dictionaries-key-value","title":"Dictionaries {key: value}","text":"<pre><code>my_dict = {\"age\":25,\"taille\":183,\"sexe\":\"F\"}\nmy_dict = {x: x ** 2 for x in range(10)}\ndict([('foo', 100), ('bar', 200)])\n\nmy_dict[\"new_key\"] = \"value\"                    # add new key with value\nmy_dict.pop(\"new_key\")                          # remove new_key.\nmy_dict.clear()                                 # Removes all the elements from the dictionary\nmy_dict.copy()                                  # Returns a copy of the dictionary\nmy_dict.fromkeys()                              # Returns a dictionary with the specified keys and value\nmy_dict.get('key')                              # Returns the value of the specified 'key'\nmy_dict.items()                                 # Returns a list containing a tuple for each key value pair\nmy_dict.keys()                                  # Returns a list containing the dictionary's keys\nmy_dict.values()                                # Returns a list of all the values in the dictionary\nmy_dict.pop()                                   # Removes the last element if no key specified\nmy_dict.popitem()                               # Removes the last inserted key-value pair\nmy_dict.setdefault()                            # Returns the value of the specified key. If the key does not exist: insert the key, with the specified value\nmy_dict.update()                                # Updates the dictionary with the specified key-value pairs\ndel my_dict[\"xxx\"]                              # remove key \"xxx\" from dict\n</code></pre> <p>shallow vs. deep copy</p> <pre><code>import copy\n\noriginal_dict = {'key1': [1, 2, 3], 'key2': {'a': 1, 'b': 2}}\nshallow_copy = original_dict.copy()\ndeep_copy = copy.deepcopy(original_dict)\nassign_copy = original_dict\n\n# Modifying the inner list\noriginal_dict['key1'].append(4)\n\nprint(f\"Id : {id(original_dict)}, {original_dict}\")         # Id : 1846091003776, {'key1': [1, 2, 3, 4], 'key2': {'a': 1, 'b': 2}}\nprint(f\"Id : {id(shallow_copy)}, {shallow_copy}\")           # Id : 1846090999232, {'key1': [1, 2, 3, 4], 'key2': {'a': 1, 'b': 2}}\nprint(f\"Id : {id(deep_copy)}, {deep_copy}\")                 # Id : 1846090994432, {'key1': [1, 2, 3], 'key2': {'a': 1, 'b': 2}}\nprint(f\"Id : {id(assign_copy)}, {assign_copy}\")             # Id : 1846091003776, {'key1': [1, 2, 3, 4], 'key2': {'a': 1, 'b': 2}}\n</code></pre>"},{"location":"python/python/#sets","title":"Sets {}","text":"<pre><code># Set creation\n{'jack', 'sjoerd'}\n{c for c in 'abracadabra' if c not in 'abc'}\nset()\nset('foobar')\nset(['a', 'b', 'foo'])\n\n# Functions\nx = set('abracadabra')                          # return unique letters of 'abracadabra'\ny = set('chti')                                 \n\nx.isdisjoint(y)                                 # returns true if x and y have no common element\n\nx.issubset(y)                                   # returns true if all elements of x are in y\nx &lt;= y                                          \n\nx.issuperset(y)                                 # returns true if all elements of y are in x\nx &gt;= y                                          \n\nx.union(y)                                      # returns new set with all elements from both x and y\nx | y                                           \n\nx.intersection(y)                               # returns a new set with elements common to x and y\nx &amp; y                                           \n\nx.difference(y)                                 # returns a new set with elements in x that are not in y\nx - y                                           \n</code></pre>"},{"location":"python/python/#counter","title":"Counter","text":"<pre><code>from collections import Counter\n\n# r\u00e9cup\u00e9ration de toutes les observations\ndata = list(\n    {'key1':value1,'key2':value2}, \n    {'key1':value1,'key2':value2, 'key3':value3}\n)\n\n# comptage du nombre de champs par document\nfields_count = list(map(lambda x: len(x), data))                # compte les cl\u00e9s de premier niveau seulement\n\n# calcul de la distribution du nombre de champs par document\ncounter = Counter(fields_count)\n# Counter({20: 675, 19: 380, 21: 174, 18: 107, 17: 4})\n# Il y a 675 objets de 20 champs etc...\n\nc = Counter(a=4, b=2, c=0, d=-2)\nd = Counter(a=1, b=2, c=3, d=4)\nc.subtract(d)\n# Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})\n\ncounter.most_common(n)                          # Returns a list of tuples of the n most frequent keys with their value\n# [('20', 675), ('19', 380), ('21', 174))]\nc.most_common()[:-n-1:-1]                       # n least common elements\n\ncounter.total()\n# N : sum of all value in the counter\n\n+counter                                        # remove zero and negative counts\n</code></pre>"},{"location":"python/python/#annotations","title":"Annotations","text":"<pre><code>def une_fonction(a:str='Hello World')-&gt;None:    # parameter and return type precised\n   print(a)\nprint(une_fonction.__annotations__)             # display annotations of a function\n{'a': str, 'return': None}\n</code></pre>"},{"location":"python/python/#functions","title":"Functions","text":""},{"location":"python/python/#display-documentation","title":"Display documentation","text":"<pre><code>help(my_function)\n</code></pre>"},{"location":"python/python/#definition","title":"Definition","text":"<pre><code>def my_function(param1=x, param2, ...):         # parameters can be any type, x is the default value of param1\n\n    \"\"\"short description of the function in one line.\n\n    Parameters:\n        param1 : la liste \u00e0 trier.\n        param2 : number of items\n\n    Return :\n        val_out : return value   \n    \"\"\"\n\n    # statments\n    ...\n\n    # result\n    return val1, val2                           # when multiple return -&gt; tuple assignment\n</code></pre>"},{"location":"python/python/#modules-packages-and-librairies","title":"Modules, Packages and Librairies","text":"<pre><code>import numpy as np                              # \"as np\" not necessary, np is an alias\nprint(numpy.cos(x))                             # if \"as np\" is not mentionned\nprint(np.cos(x))                                # if \"as np\" is mentionned\n\nfrom numpy import cos, sin, exp                 # import only the modules cos, sin, exp\n</code></pre>"},{"location":"python/python/#with-statement","title":"With Statement","text":"<pre><code>with open('file_path', 'w') as file:            # ensure that the process ends properly\n    file.write('hello world !')                 # and is equivalent to the try except approach\n\n# try except equivalent\nfile = open('file_path', 'w')\ntry:\n    file.write('hello world !')\nfinally:\n    file.close()    \n</code></pre>"},{"location":"python/python/#try-except-statement","title":"Try Except Statement","text":"<pre><code>while True:\n    try:\n        x = int(input(\"Please enter a number: \"))\n        break\n    except ValueError:\n        print(\"Oops!  That was no valid number.  Try again...\")  \n</code></pre>"},{"location":"python/python/#poo","title":"POO","text":""},{"location":"python/python/#concepts","title":"Concepts","text":"<p>Generics</p> <ul> <li>classe</li> <li>constructor</li> <li>getter and setter</li> <li>encapsulation (_ and __ are protected prefix or private but all is public in reality)</li> <li>h\u00e9ritage (multiple)</li> <li>surcharge de m\u00e9thode</li> <li>polymorphisme</li> <li>interface</li> <li>collections d'objet</li> <li>erreur</li> </ul> <p>Python</p> <ul> <li>attribut de classe/instance</li> <li>decorateurs</li> <li>methode de classe/instance/statique (@classmethod)</li> <li>propi\u00e9t\u00e9 (@property) (getter et setter)</li> </ul> <p>Best Practices</p> <ul> <li>TDD</li> <li>Design Patterns</li> <li>SOLID</li> <li>Single responsibility</li> <li>Chaque classe ou fonction doit faire une seule chose</li> <li>Open/Closed</li> <li>Les classes doivent \u00eatre ouvertes \u00e0 l\u2019extension, mais ferm\u00e9es \u00e0 la modification.</li> <li>Liskov</li> <li>Les sous-classes doivent pouvoir faire tout ce que font leurs classes parentes</li> <li>Interface Segregation</li> <li>responsabilit\u00e9 unique, appliqu\u00e9 aux interfaces.</li> <li>Dependency Inversion</li> <li>Les classes parentes ne doivent pas avoir \u00e0 changer lorsque l\u2019une de leurs sous-classes est modifi\u00e9e.</li> </ul> <p>Avoid</p> <ul> <li>STUPID</li> <li>Singleton.</li> <li>Couplage fort (\u00ab\u2009Tight coupling\u2009\u00bb).</li> <li>Non-testabilit\u00e9 (\u00ab\u2009Untestability\u2009\u00bb).</li> <li>Optimisation pr\u00e9matur\u00e9e (\u00ab Premature optimization \u00bb).</li> <li>Nommage non descriptif (\u00ab Indescriptive naming \u00bb).</li> <li>Duplication.</li> </ul>"},{"location":"python/python/#class-definition","title":"Class Definition","text":"<pre><code>class Car:\n\n    \"\"\"La classe Car permet de construire une voiture.\n\n    Param\u00e8tres\n    ----------\n    color : Cha\u00eene de caract\u00e8res : Couleur de la voiture.\n    model : Cha\u00eene de caract\u00e8res : Mod\u00e8le de la voiture.\n    horsepower : Entier : Cylindr\u00e9e de la voiture.\n\n    Example\n    -------\n    aventador = Car(color = \"orange\", model = \"Aventador\", horsepower = 700)\n    \"\"\"\n\n    # Definition of class variable\n    n_cars = 0\n\n    # D\u00e9finition du constructeur de la classe Car\n    def __init__(self, color, model, horsepower):\n       # Initialisation des attributs de la classe avec les arguments du constructeur\n        self.color = color\n        self.model = model\n        self.horsepower = horsepower\n\n    # D\u00e9finition d'une m\u00e9thode permettant de changer la couleur d'une voiture\n    def change_color(self, new_color):\n        \"\"\"Modifie la couleur d'une voiture.\n\n        Param\u00e8tres\n        ----------\n        new_color : string : Nouvelle couleur de la voiture.\n        \"\"\"\n        self.color = new_color\n\n# instanciation\naventador = Car(color = \"orange\",               # Cr\u00e9ation d'un objet de la classe Car\n                model = \"Aventador\",\n                horsepower = 700)\n\n# display class documentation\nhelp(Car)\n</code></pre>"},{"location":"python/python/#heritage","title":"Heritage","text":"<pre><code>class Vehicule: \n    def __init__(self, a, b = []):\n        self.seats = a \n        self.passengers = b \n\n    def add(self,name):\n            self.passengers.append(name)\n\nclass Moto(Vehicule): # heritate from Vehicule\n    def __init__(self, b, c):\n        self.seats = 2\n        self.passengers = b\n        self.brand = c\n</code></pre>"},{"location":"python/python/#polymorphism","title":"Polymorphism","text":"<pre><code>class Vehicule: \n    def __init__(self, a, b = []):\n        self.seats = a  \n        self.passengers = b\n\n    def add(self,name):\n            self.passengers.append(name)\n\nclass Moto(Vehicule):\n    def __init__(self, b, c):\n        self.seats = 2\n        self.passengers = b\n        self.brand = c\n\n    def add(self, name): # polymorphism\n        if( len(self.passengers) &lt;  self.seats):\n            self.passengers.append(name)\n            print('Il reste', self.seats - len(self.passengers), 'places')\n        else:\n            print(\"Le v\u00e9hicule est rempli\")\n</code></pre>"},{"location":"python/python/#built-in-functions","title":"Built in Functions","text":"<p>Python Doc</p> <pre><code>all(iterable)                                   # Return True if all elements of the iterable are true (or if the iterable is empty)\nany(iterable)                                   # Return True if any element of the iterable is true. If the iterable is empty, return False.\nchr(i)                                          # chr(97) returns the string 'a' (invers of ord())\ndelattr(object, name)                           # delattr(x, 'foobar') is equivalent to del x.foobar\ndict(iterable, **kwarg)                         # Create a new dictionary\ndir(list)                                       # displays attributes and methods of object 'list'\nhelp(list)                                      # displays documentation of object 'list'\nisinstance(object, classinfo)                   # Return True if the object argument is an instance of the classinfo argument\niter(object[, sentinel])                        # Return an iterator object.\nmap(function, iterable, ...)                    # Return an iterator that applies function to every item of iterable, yielding the results\nord(c)                                          # ord('a') returns the integer 97 and ord('\u20ac') returns 8364\nopen(file, mode='r',...)                        #\npow(base, exp[,mod])                            # Return base to the power exp; if mod is present, return base to the power exp, modulo mod (computed more efficiently than pow(base, exp) % mod)\nzip(*iterables, strict=False)                   # Iterate over several iterables in parallel, producing tuples with an item from each one\n\n'__class__',\n'__delattr__',\n'__dir__',\n'__doc__',\n'__eq__',\n'__format__',\n'__ge__',\n'__getattribute__',\n'__gt__',\n'__hash__',\n'__init__',\n'__init_subclass__',\n'__le__',\n'__lt__',\n'__ne__',\n'__new__',\n'__reduce__',\n'__reduce_ex__',\n'__repr__',\n'__setattr__',\n'__sizeof__',\n'__str__',                                     # when own class : better than method like display() \n'__subclasshook__'\n\n# redefine built-in\nClass Complexe:\n    ...\n    def mod(self):\n        return np.sqrt(self.partie_re**2 +      # renvoie (sqrt(a\u00b2 + b\u00b2))\n        self.partie_im**2)\n\n    def __lt__(self, other):                    # new built-in method __lt__ redefined\n        return self.mod().__lt__(other)\n\nz1 = Complexe(3,4)\nz2 = Complexe(2,-5)\nprint(z1&lt;z2)                                    # prints True\n</code></pre>"},{"location":"python/python/#decorators","title":"Decorators","text":"<p>Predefined Decorators</p> <pre><code>@functools.wrap(func)                           # keep properties with func\n@functools.lru_cache()                          # speed up execution time\n</code></pre> <p>Decorator with no arguments and return nothing</p> <pre><code>def do_twice(func):\n    def wrapper_do_twice():\n        func()\n        func()\n    return wrapper_do_twice\n\n@do_twice\ndef say_whee():\n    print(\"Whee!\")\n\n# results ############################################# \n# Whee!\n# Whee!\n</code></pre> <p>Decorator with arguments and return nothing</p> <pre><code>def do_twice(func):\n    def wrapper_do_twice(*args, **kwargs):              # *args, **kwargs added\n        func(*args, **kwargs)                           # *args, **kwargs added\n        func(*args, **kwargs)                           # *args, **kwargs added\n    return wrapper_do_twice\n\n@do_twice\ndef greet(name):\n    print(f\"Hello {name}\")\n\ngreet(\"World\")\n\n# results ############################################# \n# Hello World\n# Hello World\n</code></pre> <p>Decorator with arguments and return something</p> <pre><code>def do_twice(func):\n    def wrapper_do_twice(*args, **kwargs):\n        func(*args, **kwargs)\n        return func(*args, **kwargs)                    # return added\n    return wrapper_do_twice\n\n@do_twice\ndef return_greeting(name):\n    print(\"Creating greeting\")\n    return f\"Hi {name}\"\n\nreturn_greeting(\"Adam\")\n\n# results ############################################# \n# Creating greeting\n# Creating greeting\n# 'Hi Adam'                                             # return value of the last execution sent\n</code></pre> <p>Decorator with arguments</p> <pre><code>def repeat(num_times):\n    def decorator_repeat(func):\n        @functools.wraps(func)\n        def wrapper_repeat(*args, **kwargs):\n            for _ in range(num_times):\n                value = func(*args, **kwargs)\n            return value\n        return wrapper_repeat\n    return decorator_repeat\n\n@repeat(num_times=4)\ndef greet(name):\n    print(f\"Hello {name}\")\n\ngreet(\"World\")\n\n# results ############################################# \n# Hello World\n# Hello World\n# Hello World\n# Hello World\n</code></pre> <p>Decorator chained <pre><code>def print_before_execution(function):\n    def print_then_execute(*args, **kwargs):\n        print('voici ce que renvoie la fonction {}'.format(function.__name__))\n        function(*args, **kwargs)\n    return print_then_execute\n\ndef print_after_execution(function):\n    def execute_then_print(*args, **kwargs):\n        function(*args, **kwargs)\n        print('La fonction a fini de tourner')\n    return execute_then_print\n\n@print_after_execution\n@print_before_execution\ndef print_hello_world():\n    print('hello world')\n\nprint_hello_world()\n\n# results ############################################# \n# voici ce que renvoie la fonction print_hello_world\n# hello world\n# La fonction a fini de tourner\n</code></pre></p>"},{"location":"python/python/#threading","title":"Threading","text":"<pre><code>from threading import Thread\n\ndef calcul(x):\n    x*x\n\nth=Thread(target=calcul,args=(5,))                  # create thread\nth.start()                                          # start thread \nth.join()                                           # completion of thread\n</code></pre>"},{"location":"python/python/#multiprocessing","title":"Multiprocessing","text":"<pre><code>from multiprocessing import Pool\n\ndef f(x):\n    return x*x\n\nif __name__ == '__main__':\n    with Pool(5) as p:                              # number of process (max ~ 60x Windows)\n        print(p.map(f, [1, 2, 3]))                  # apply f to 1, 2 and 3 on 5 processes      \n</code></pre> <p>The Process class has equivalents of all the methods of threading.Thread <pre><code>from multiprocessing import Process\n\ndef f(name):\n    print('hello', name)\n\nif __name__ == '__main__':\n    p = Process(target=f, args=('bob',))\n    p.start()\n    p.join()\n</code></pre></p>"},{"location":"python/python/#coroutines","title":"Coroutines","text":"<pre><code>asyncio.run(func())                                 # run coroutine func() \n                                                    # This function always creates a new event loop and closes it at the end. \n                                                    # It should be used as a main entry point for asyncio programs, \n                                                    # and should ideally only be called once\n\nawait func()                                        # run coroutine in Jupyter Notebook\nawait asyncio.gather(name_async('Daniel'),          # gather async function and run them with await\n                     name_async('Donna'),           # result is an aggregate list of returned values\n                     name_async('Diane'))\n\nasyncio.ensure_future(name_async())                 # create task for concurrency\nasyncio.create_task(name_async())                   # create task for concurrency (preferred way)\n</code></pre>"},{"location":"python/python/#tests","title":"TESTS","text":""},{"location":"python/python/#librairies","title":"Librairies","text":"<ul> <li>unittest (avec classe)</li> <li>pytest (sans classe)</li> <li>doctest (standard library)</li> </ul>"},{"location":"python/python/#strategie-de-test","title":"Strat\u00e9gie de test","text":"<ul> <li>Tester l'INTERFACE des objets</li> <li>3 sens de messages : entrants, internes et sortants.</li> <li>2 types : requ\u00eate et commande<ul> <li>entrants:<ul> <li>requ\u00eate &gt; test avec assertions avec ce quelle doivent renvoyer</li> <li>commande &gt; assert avec les changements directs</li> </ul> </li> <li>internes:<ul> <li>requ\u00eate &gt; ignorer (car si le test entrant se passe bien &gt; le fonctionnement interne est OK)</li> <li>commande &gt; ignorer</li> </ul> </li> <li>sortants:<ul> <li>requ\u00eate &gt; ignorer</li> <li>commande &gt; attendre \u00e0 envoyer / utiliser des mocks</li> </ul> </li> </ul> </li> </ul>"},{"location":"python/python/#doctest","title":"Doctest","text":"<pre><code>import doctest\n\ndef add(a, b):\n    \"\"\"\n    Given two integers, return the sum.\n\n    :param a: int\n    :param b: int\n    :return: int\n\n    &gt;&gt;&gt; add(2, 3)\n    5\n    &gt;&gt;&gt; add(3, 3)\n    6\n    \"\"\"\n    return a + b\n\ndoctest.testmod()\n\n###\nOutput\nTestResults(failed=0, attempted=1)\n</code></pre> <ul> <li> <p>Tester avec : python -m doctest -v program/world.py</p> </li> <li> <p>Sinon cr\u00e9er un fichier de test \u00e0 part:</p> <ul> <li>Ecrire d'abord les tests en texte puis impl\u00e9menter les en classes</li> </ul> </li> </ul>"},{"location":"python/python/#pytest","title":"PyTest","text":"<ul> <li>recherche <code>test_*.py</code> ou <code>*_test.py</code></li> <li>recherche ensuite les fonctions et m\u00e9thodes en dehors des classes commen\u00e7ant par <code>test</code></li> <li>recherche ensuite les fonctions et m\u00e9thodes pr\u00e9fixer par <code>test</code> dans les classes commen\u00e7ant par <code>Test</code></li> <li>cr\u00e9er des mock avec monkey...</li> <li>setup() : avant test - setup_module(module), setup_method(self, method), setup_function(function)</li> <li>teardown() : apr\u00e8s test</li> </ul> <pre><code>pip3 install pytest\npython3 -m pytest code1_test.py   # python3 -m not mendatory\n</code></pre>"},{"location":"python/python/#coverage","title":"Coverage","text":"<pre><code>pip install coverage\npip install pytest-cov\n\npytest --cov=program --cov-report html test_*.py\n# cr\u00e9e:\n# - 1 fichier HTML \"index.html\" dans le dossier \"htmlcov\" qui affiche le tableau de coverage\n# - 1 fichier HTML par fichier test\u00e9 pour le d\u00e9tail\n</code></pre>"},{"location":"python/python/#libraries","title":"LIBRARIES","text":""},{"location":"python/python/#os","title":"os","text":"<pre><code>import os\n\npath = \"/home/olivier/scripts/cgi-bin/action.py\"\nos.path.dirname(path)\n'/home/olivier/scripts/cgi-bin'\n\nos.path.basename(path)\n'action.py'\n\nos.path.join(path, \"func\")\n'/home/olivier/scripts/cgi-bin/action.py/func'\n\nos.path.split(path)\n('/home/olivier/scripts/cgi-bin', 'action.py')\n\nos.path.abspath(\".\")\n'/home/olivier'\n\nos.listdir(\"/home/olivier\")\n['.bash_history', 'Images', 'script.py']\n\nos.makedirs(path)                                   # Cr\u00e9er r\u00e9cursivement tous les dossiers d'un path si ceux-ci n'existent pas\nos.mkdir(path)                                      # Cr\u00e9er le dernier dossier d'un path. Si un des dossiers n'existe pas une erreur est retourn\u00e9e\nos.remove(path)                                     # Supprime le fichier / dossier indiqu\u00e9\nos.rename(old, new)                                 # Renomme le fichier / dossier indiqu\u00e9\n\nFILE = os.path.realpath(os.path.join(os.path.dirname(__file__), '..','data', 'api_keys.txt')) # translate \"..\" into real path\n\n\nfolder_path = \"/mnt/box/files\"\nfor path, dirs, files in os.walk(folder_path):\n    for filename in files:\n        print(filename)\n</code></pre>"},{"location":"python/python/#dotenv","title":"dotenv","text":"<pre><code>pip install python-dotenv\n</code></pre> <pre><code>from dotenv import load_dotenv\n\nload_dotenv()  # take environment variables from .env.\n\n# Code of your application, which uses environment variables (e.g. from `os.environ` or\n# `os.getenv`) as if they came from the actual environment.\n</code></pre> <pre><code>from dotenv import dotenv_values\n\nconfig = dotenv_values(\".env\")  # config = {\"USER\": \"foo\", \"EMAIL\": \"foo@example.org\"}\n</code></pre> <pre><code>import os\nfrom dotenv import dotenv_values\n\nconfig = {\n    **dotenv_values(\".env.shared\"),  # load shared development variables\n    **dotenv_values(\".env.secret\"),  # load sensitive variables\n    **os.environ,  # override loaded values with environment variables\n}\n</code></pre>"},{"location":"python/python/#random","title":"random","text":"<p>Pas pour des projets de s\u00e9curit\u00e9 (cf. module \"secrets\") <pre><code>random.randint(a, b)\nrandom.choice(seq)                                                  # choose one item among list \"seq\"\nrandom.choices(population, weights=None,*, cum_weights=None, k=N)   # random draw N item among population\nrandom.shuffle(x[, random])\nrandom.sample(population, k, *, counts=None)\nrandom.random()\nrandom.uniform(a, b)\nrandom.gauss(mu, sigma)\n</code></pre></p>"},{"location":"python/python/#argparse","title":"argparse","text":"<pre><code>import argparse\n\nparser = argparse.ArgumentParser(description='Process some integers.')\nparser.add_argument('integers', metavar='N', type=int, nargs='+',\n                    help='an integer for the accumulator')\nparser.add_argument('--sum', dest='accumulate', action='store_const',\n                    const=sum, default=max,\n                    help='sum the integers (default: find the max)')\n\nargs = parser.parse_args()\nprint(args.accumulate(args.integers))\n</code></pre>"},{"location":"python/python/#logging","title":"logging","text":"<pre><code>import logging\n\n# Logging level\nlogging.basicConfig(encoding='utf-8', level=logging.DEBUG)\n\nlogging.info('Request success : %d', response.status_code)\nlogging.error('Request failure : %s', str(e))\n</code></pre>"},{"location":"python/python/#json","title":"json","text":"<pre><code>import json\n\n# export to json and format with indent (else just one line)\nwith open('arrivals.json', 'w') as f:\n    json.dump(arr.json(), f, indent=4)\n\n# deal with unicode character\nwith open(\"updates.json\", \"w\", encoding=\"utf-8\") as f:\n        json.dump(poi_new_schema, f, indent=4, ensure_ascii=False, default=str)   \n\n# export list to JSON file\nlist = [{'key':'value','key2':'value'},{'key':'value','key2':'value'},...]\nwith open('arrivals.json', 'w') as f:\n    json.dump(list, f, indent=4)\n\n# convert dict to JSON object\nobj = json.dumps(market_data, default=pydantic_encoder)\n\n# import json file\nwith open('departures.json') as f:\n    dep = json.load(f)\n\n# string to JSON (plusieurs doc JSON import\u00e9s depuis un fichier \u00e0 retransform\u00e9\nwith open('airlines.json','r') as f:\n    lines = f.readlines()\n    for line in lines:\n        l=json.loads(line)          # l est au format JSON et line string\n        ...\n\n# Export to JSON 1 line / document\nwith open('airports.json', 'w') as f:\n    for a in airports[\"Airport\"]:\n        json.dump(a, f)\n        f.write('\\n')\n\n# convert string to JSON\nindex = \"\"\"\n[\n  {\n    \"label\": \"VILLA GALLO-ROMAINE DU GROSSWALD\",\n    \"lastUpdateDatatourisme\": \"2023-01-01T05:07:52.747Z\",\n  },\n  {\n    \"label\": \"PARC DU TONNEAU\",\n    \"lastUpdateDatatourisme\": \"2023-01-02T05:07:52.747Z\",\n  }\n]\n\"\"\"\nind = json.loads(index)\nfor i in ind:\n    print(type(i))                  # i est un dict\n</code></pre>"},{"location":"python/python/#pickle","title":"pickle","text":"<p>Serializing : Save the state of an object into memory or a file (.pkl for example) Deserializing : retrieve an object from memory or a file (.pkl for example)</p> <p>Formats for serializing : <code>pickle</code>, <code>JSON</code>, <code>XML</code>, <code>HDF5</code></p> <p>Advantages of Pickle : - can serialize almost every commonly used built-in Python (unlike JSON...) - good choice when storing recursive structures since it only writes an object once.</p> <p>Disadvantages of Pickle :  - unsafe because it can execute malicious Python callables to construct objects. - Python-specific module, and you may struggle to deserialize pickled objects when using a different language. - appears to be slower and produces larger serialized values than formats such as JSON and ApacheThrift.</p> <pre><code># save object\npickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)\npickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)\n\n# retrieve object\npickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)\npickle.loads(data, /, *, fix_imports=True, encoding=\u201dASCII\u201d, errors=\u201dstrict\u201d, buffers=None)\n</code></pre> <p>Write CSV vs Pickle <pre><code># write to CSV\nstart = time.time()\ndf.to_csv('pandas_dataframe.csv')\nend = time.time()\nprint(end - start)\n-------\n0.19349145889282227\n\n\n# write to Pickle\nstart = time.time()\ndf.to_pickle(\"my_pandas_dataframe.pkl\")\nend = time.time()\nprint(end - start)\n-------\n0.0059659481048583984\n</code></pre></p> <p>Read CSV vs Pickle <pre><code># Reading the csv file into Pandas:\nstart1 = time.time()\ndf_csv = pd.read_csv(\"my_pandas_dataframe.csv\")\nend1 = time.time()\nprint(end - start)\n-------\n0.00677490234375\n\n\n# Reading the Pickle file into Pandas:\nstart2 = time.time()\ndf_pkl = pd.read_pickle(\"my_pandas_dataframe.pkl\")\nend2 = time.time()\nprint(end2 - start2)\n-------\n0.0009608268737792969\n</code></pre></p> <p>ML Models</p> <p>Pickle allows to serialize machine learning models in their existing state. It makes it possible to use them again as needed.</p> <pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import make_regression\n\n# generate regression dataset\nX, y = make_regression(n_samples=100, n_features=3, noise=0.1, random_state=1)\n\n# train regression model\nlinear_model = LinearRegression()\nlinear_model.fit(X, y)\n\n# summary of the model\nprint('Model intercept :', linear_model.intercept_)\nprint('Model coefficients : ', linear_model.coef_)\nprint('Model score : ', linear_model.score(X, y))\n------\nModel intercept : -0.010109549594702116\nModel coefficients :  [44.18793068 98.97389468 58.17121618]\nModel score :  0.9999993081899219\n\n# Serializing\nwith open(\"linear_regression.pkl\", \"wb\") as f:\n    pickle.dump(linear_model, f)\n</code></pre> <pre><code># Deserializing\nwith open(\"linear_regression.pkl\", \"rb\") as f:\n    unpickled_linear_model = pickle.load(f)\n\n# summary of the model\nprint('Model intercept :', unpickled_linear_model.intercept_)\nprint('Model coefficients : ', unpickled_linear_model.coef_)\nprint('Model score : ', unpickled_linear_model.score(X, y))\n------\nModel intercept : -0.010109549594702116\nModel coefficients :  [44.18793068 98.97389468 58.17121618]\nModel score :  0.9999993081899219\n</code></pre> <p>Speeding up</p> <p>Pickle <pre><code>start = time.time()\nwith open(\"df1.pkl\", \"wb\") as f:\n    pickle.dump(data, f)\nend = time.time()\nprint(end - start)\n------\n0.006001710891723633\n</code></pre></p> <p>PROTOCOL property <pre><code>start = time.time()\nwith open(\"df2.pkl\", \"wb\") as f:\n    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n    end = time.time()\nprint(end - start)\n------\n0.0030384063720703125```\n\n*cPickle*\n```python\nstart = time.time()\nwith open(\"df3.pkl\", \"wb\") as f:\n    cPickle.dump(data, f)\nend = time.time()\nprint(end-start)\n------\n0.004027366638183594\n</code></pre></p>"},{"location":"python/python/#numpy","title":"numpy","text":"<p>fast numerical calculation numpy website</p> <p>create table <pre><code>import numpy as np\n\nX = np.zeros(shape = (5, 10))                       # Cr\u00e9ation d'une matrice de dimensions 5x10 remplie de z\u00e9ros\nX = np.ones(shape = (3, 10, 10))                    # Cr\u00e9ation d'une matrice \u00e0 3 dimensions 3x10x10 remplie de uns\nX = np.array([2*i for i in range(10)])              # [0, 2, 4, 6, ..., 18] Cr\u00e9ation d'un array \u00e0 partir d'une liste d\u00e9finie en compr\u00e9hension\nX = np.array([[1, 3, 3],                            # Cr\u00e9ation d'un array \u00e0 partir d'une liste de listes\n              [3, 3, 1],\n              [1, 2, 0]])\n\nnp.linspace(start = 0.01, stop = 0.15, num = 15))   # [0.01, 0.02, ..., 0.15] define 1D array with number of values\n\n\nX_1 = np.ones(shape = (2, 3))\nX_2 = np.zeros(shape = (2, 3))\nX_3 = np.concatenate([X_1, X_2], axis = 0)          # Concatenate arrays with care to dimensions (axis 0 = rows, axis 1 = columns)\n\n# defines array with step size\nnp.arange(3)                                        # returns array([0, 1, 2])\nnp.arange(3,7)                                      # returns array([3, 4, 5, 6])\nnp.arange(3,7,2)                                    # defines array([3, 5]) with step size\n\nx = np.array([0.2, 6.4, 3.0, 1.6])\nbins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\ninds = np.digitize(x, bins)                         # inds returns array([1, 4, 3, 2])\n</code></pre></p> <p>select and slicing <pre><code>X[4, 3]                                             # affichage de l'\u00e9l\u00e9ment \u00e0 l'index (4, 3)\nX[1, 5] = -1                                        # assignation de la valeur -1 \u00e0 l'\u00e9l\u00e9ment d'index (1, 5)\nX[X&lt;0] = 0                                          # conditionnal assignment\nX[1:4, 2:9, 5:7]                                    # slicing N dimension (n\u00e9gative possible)\n\n\nX = np.array([3, -7, -10, 3, 6, 5, 2, 9])\ny = np.array([0, 1, 1, 1, 0, 1, 0, 0]) \nX[y == 1] = -1                                      # On assigne la valeur -1 aux \u00e9l\u00e9ments de X pour lesquels la valeur de y \u00e0 l'indice correspondant vaut 1\nprint(X[y == 0])                                    # Affichage des \u00e9l\u00e9ments de X pour lesquels la valeur de y \u00e0 l'indice correspondant vaut 0\n</code></pre></p> <p>math functions <pre><code>np.exp(x)\nnp.abs(x)\nnp.log(x)\nnp.sin(x)\nnp.cos(x)\nnp.round(x, decimals = n)\n</code></pre></p> <p>shape <pre><code>X.shape                                             # X dimensions ex: (3,4)\nX = [1  2  3  4  5  6  7  8  9 10]                  # reshaping (must have same number of elements)\nX_reshaped = X.reshape((2, 5))\n[[1  2  3  4  5]\n  [6  7  8  9 10]]\n</code></pre> operations <pre><code>M*N                                                 # product element by element wirh *\nM.dot(N)                                            # matrix product with dot()\n\nnp.where(probs[:,1]&gt;0.4,1,0)                        # returns 1 if probs[:,1]&gt;0.4, 0 else\n</code></pre></p> <p>broadcasting <pre><code># broadcasting matrix and constante\nM=[[ 1  2  3  4  5]\n  [ 6  7  8  9 10]]\nc=4                                                 \nM+c                                                 # c is transformed in a matrix of shape M\n[[ 5  6  7  8  9]\n  [ 10  11  12  13 14]]\n\n# broadcasting matrix and vector (check for same dimension or dimension 1)\nM=[[ 3 1 2]\n   [-2 1 5]]\nv=[[2]    =&gt;    v=[[2 2 2]                          # v is broadcasted on his dimension of size 1\n   [5]]            [5 5 5]]\nM*v=[[ 6 2 4]\n     [-10 5 25]]\nu=[[3 4]]\nv+u=[[2 2]   +   [[3 4]                             # v and u are broadcasted on their dimension of size 1\n     [5 5]]       [3 4]]                                \n\n # Le broadcasting nous permet de faire cette op\u00e9ration sans boucle for sur les lignes\nX_tilde[:, j] = (X[:,j]-min_Xj)/(max_Xj-min_Xj)     # operate on each item of column j \n</code></pre></p> <p>statistics <pre><code>A = np.array([[1, 1, 10],\n              [3, 5, 2]])\n\nA.mean(axis=0)                                      # return mean on columns\nA.sum(axis=0)                                       # return sum\nA.std(axis=0)                                       # return standard deviation\nA.min(axis=0)                                       # return min\nA.max(axis=0)                                       # return max\nA.argmin(axis=0)                                    # return index of min value\nA.argmax(axis=0)                                    # return index of max value\n</code></pre></p>"},{"location":"python/python/#pandas","title":"pandas","text":"<p>Library for manipulating and analyze data pandas website</p> <p>DataFrame</p> <p>Un DataFrame est une matrice (dont chaque ligne et chaque colonne porte un indice)  qui sert \u00e0 stocker des bases de donn\u00e9es. La colonne contenant les num\u00e9rotations des lignes est appel\u00e9e l'index et ne se g\u00e8re pas de la m\u00eame fa\u00e7on qu'une colonne du dataset</p> <p>Indexation : - par d\u00e9faut (num\u00e9ros des lignes) - une des colonnes du DataFrame - liste que l'on d\u00e9finit nous-m\u00eame</p> <p>Diff\u00e9rence avec array Numpy - un DataFrame est beaucoup plus lisible - le type des \u00e9l\u00e9ments peut varier - La classe DataFrame contient davantage de m\u00e9thodes pour la manipulation et le pr\u00e9-traitement de bases de donn\u00e9es</p> <p>create df <pre><code>import pandas as pd                             # import pandas with alias pd\npd.DataFrame(data, index, columns, ...)         # data = np.array/liste/dict/pd.DataFrame\n\ndictionnaire = {\"Produit\"          : ['miel', 'farine', 'vin'],\n                \"Date d'expiration\": ['10/08/2025', '25/09/2024', '15/10/2023'],\n                \"Quantit\u00e9\"         : [100, 55, 1800], \n                \"Prix \u00e0 l'unit\u00e9\"   : [2, 3, 10]}\ndf = pd.DataFrame(dictionnaire)                 # load data from a dictionary\n\n# load from multipule existing list\ndf = pd.DataFrame(list(zip(titre_SC,annee_sortie_SC,note_SC)), \n                  columns=[\"Titre\",\"Annee_sortie_SC\",\"Note_SC\"])\n\n\ndf = pd.read_csv(filepath_or_buffer,            # load data with CSV\n                 sep = ',',                     # Add ?raw=true at the end of the https:// filename if it fails\n                 header = 0,\n                 index_col = 0)\n\n\npd.set_option('display.max_columns', None)      # set this to see all the columns at a time           \n</code></pre></p> <p>overview of df <pre><code>df.dtypes                                       # return columns type \ndf.info()                                       # columns infos\npd.to_datetime(df['date_operation'])            # convert column to date type\ndf.describe()                                   # for the whole dataset\ndf['col'].value_counts()                        # Counting unique categorical variable. must be done on one column\ndf['col'].value_counts(dropna=False)            # Counting occurences as well as missing values\ndf['col'].value_counts(normalize=True)          # get the relative frequency\ndf.head()                                       # display first rows (5 by default)\ndf.tail()                                       # display last rows (5 by default)\ndf.columns                                      # return a list of column\ndf.columns = [col.lower().replace(\" \",\"_\")      # lower column name and replace ' ' by '_'\n                for col in df.columns]\ndf.shape                                        # return a tuple of the shape\nlen(df)                                         # number of rows\nlen(df.columns)                                 # number of columns\ndf.size                                         # number of elements\n\npd.crosstab(index=df['col1'],                   # table with number of rows containing both item from col1 \n            columns=df['col2'],                 # and item from col2\n            rownames=None, colnames=None        # name of index and column for the new table\n            margins=False,                      # margins count the total amount of one row or column\n            margins_name=\"Total\",               #\n            dropna=True,                        # \n            normalize=False)                    # percentage of time each combination occurs\n                                                # - all or True: from total population,\n                                                # - index : will normalize over each row\n                                                # - column : will normalize over each row\n\npd.crosstab(df['col1'],\n            [df['col7'],df['col4'],])\n</code></pre> statistics <pre><code>df.select_dtypes(include='number')              # select only numerical features in df\ndf.select_dtypes(include='O')                   # select only string features in df\ndf.mean()                                       # df mean\ndf.median()                                     # df median\ndf['col'].quantile(q=[0.25,0.5,0.75])           # col quantiles \ndf['col'].std()                                 # col std\ndf['col'].between(int1,int2).astype(int)        # boolean true if value in col is between int1 and int2 (cast as int)\n\npd.qcut(df['col'], 4, labels=['q1', 'q2', 'q3', 'q4'])  # Discretize variable into equal-sized buckets based on rank or based on sample quantiles\n</code></pre></p> <p>Select/locate Lorsque nous pr\u00e9parons un jeu de donn\u00e9es pour l'exploiter plus tard,  il est pr\u00e9f\u00e9rable de s\u00e9parer les variables cat\u00e9gorielles des variables quantitatives <pre><code># new dataframe df from df transactions\ndf = transactions['cust_id']                    # extract one column\ndf = transactions[[\"cust_id\",\"Qty\"]]            # extract multiple column\n\n# select rows from a df with loc (multiple  results if index not unique)\ndf.loc[index]                                   # index can be list of index or slicing (indexes must be unique in that case)\ndf.loc[[idx1, idx2, ...]]  \ndf.loc[[indexrows][columns]]                    # columns to extract\ndf.loc[(df['col'] == 'toto'),'col']='new_val'   # replace value based on conditions                 \n\n# select rows from a dataframe with iloc (like for a numpy array)\ndf.iloc[0:4, 0:3]                               # only with numerical index of rows and columns\n\ndf1 = df[df.columns[:4]]                        # select first 4 column [0..3]\ndf2 = df[df.columns[4:]]                        # select from 4th column until last [4..n]\n</code></pre></p> <p>Conditionnal indexing of df <pre><code># 2 way:\ndf[df['col 2'] == 3]                            # return only a copy. cannot be used for assignment\ndf.loc[df['col 2'] == 3]                        # must be used if assignment\n\n\ndf[~(df['col']) &gt; 1]                            # not ~\ndf[(df['col'] &lt; -1) | (df['col'] &gt; 2)]          # or |\ndf[(df['col'] &gt; -1) &amp; (df['col'] &lt; 2)]          # and &amp;\n</code></pre></p> <p>transform <pre><code>df.duplicated()                                 # show duplicates\ndf.replace('AUS', 1)                            # replace each item 'AUS' with 1\ndf.loc[(df['col'] == 'toto'),'col']='new_val'   # replace value based on conditions  \ndf.rename({'old_name': 'new'}, axis = 1)        # rename column 'old_name' with 'new' \ndf = df.astype({'col': 'int'})                  # change column type of 'col' to 'int'\ndf['col'] = df['col'].astype('int')             #\ndf['col'] = pd.to_numeric(df[\"col\"],errors='X') # convert col type to numeric (float64 or int64 depending on the data supplied) X = 'raise', 'ignore', 'coerce'\ndf.drop(['price'], axis = 1)                    # remove 'price' column\ndf = df.drop(df[(df.col == 50) &amp;                # remove lines where col = 50 and col2 = toto\n                (df.col2 == 'toto')].index)     # \ndf['col1'].apply(func1)                         # apply func1 to every item of col1\n\n# Pay attention with following\ndf.set_value('row', 'col', value)               # set value to [row,col] item\ndf.at['row', 'col'] = value                     # set value to [row,col] item\n\ns.str.len()                                     # length of each string element  \ns.str.upper()                                   # uppercase letters\ns.str.lower()                                   # lowercase letters\ns.str.capitalize()                              # Uppercase first letter\ns.str.swapcase()                                # swap upper to lower and vice versa\ns.str.title()                                   # Uppercase first letter of each word\ns.str.strip('%')                                # remove '%' from right and left of s\ns.str.join('-')                                 # concatenate list element in Series with '-'. NaN if one element is not a string\ns.str.split(',', n=1, expand=True)              # expand lets the split values in separate column\n\n# remove accents from column 'Titre'\ndf[\"Titre\"] = df[\"Titre\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n\nlist(df.itertuples(index=False, name=None))     # returns list of tuples (as row of df)\n\n# discretisation\ntest_gre = pd.cut(x = df['gre'],\n                  bins = [200, 450, 550, 620, 800],\n                  labels = ['mauvais', 'moyen', 'moyen +', 'bon'])\n\n# dichotomisation / one hot encoding\none_hot = pd.get_dummies(df_items[\"subtype\"], dtype=int, drop_first=False)\ndf_items_one_hot = df_items.join(one_hot)\n</code></pre></p> <p>missing values <pre><code># detection\ndf.isna()                                       # return a df with True or false for each value\ndf.isna().any(axis = 0)                         # columns with at least 1 NaN return true\ndf.isna().any(axis = 1)                         # rows with at least 1 NaN return true\ndf[df.isna().any(axis = 1)]                     # conditionnal indexing to return only rows with NaN\ndf.isnull().sum(axis = 0)                       # number of NaN by column\ndf.loc[df['col'].isnull(),:]                    # show rows of NaN for 'col'\n\n# Adding missing values\ndf.loc[[1, 3, 44, 99, 103], ['cp']] = np.NaN    # add 5 NaN in column 'cp'\ndf.iloc[[1, 3, 44, 99, 103], 12] = np.NaN       # add 5 NaN in 13th column\n\n# replacement   \ndf.fillna(0)                                    # replace all NaN with 0\ndf.fillna(df.mean())                            # replace all NaN with df mean (could be median, min,max...)\ndf['col'].fillna(-1)                            # replace NAN of 'col' by -1\ndf['col'].mode()[0]                                # mode of'col'\ndf['col'].fillna(df['col'].mode()[0])           # replace NAN of 'store_type' by his mode\ndf['col'] = df['col'].replace(np.nan, 0)        # replace NaN of column 'col' by 0\n\n# remove    \ndf.dropna(axis = 0, how = 'any')                # remove rows if at least 1 NaN in the row\ndf.dropna(axis = 1, how = 'all')                # remove columns if all NaN in the column\ndf.dropna(axis = 0, how = 'all',                # remove rows if all NaN in the 3 columns\n          subset = ['col2','col3','col4'])  \n</code></pre></p> <p>processing <pre><code># merge \npd.concat([df1,df2], axis = 1)                  # concat df1 and df2 horizontally and fill with NaN if not same number of rows\ndf1.merge(right = df2,                          # right join df1 and df2 on 'col'\n          on = 'col', how = 'right')    \ndf.set_index('Nom')                             # set new index for df with column 'Nom'\ndf.reset_index()                                # reset default index\ndf.reset_index(drop=True)                       # reset default index \ndf.index                                        # get index of df\n\n# sort\ndf.sort_values(by = 'col', ascending = True)\ndf.sort_values(by = ['col1', 'col3'], ascending = True)\n\n# group, agg\nfunctions_to_apply = {\n    'col1' : ['min', 'max', 'sum'],\n    'col3' : func1\n    }\ndf.groupby('col').agg(functions_to_apply)\ndf.groupby(['nom_dept']).agg({'count':['sum','mean']})\ndf.groupby('UTC_Offset').count().sort_values(by='IATA_Airport',ascending=False)[['IATA_Airport']]\n\n# nomalization\nnormalized_df=(df-df.mean())/df.std()           # mean normalization\nnormalized_df=(df-df.min())/(df.max()-df.min()) # min-max normalization\n</code></pre></p> <p>plot <pre><code># Diagramme en secteurs\ndata[\"categ\"].value_counts(normalize=True).plot(kind='pie')\n# Cette ligne assure que le pie chart est un cercle plut\u00f4t qu'une \u00e9llipse\nplt.axis('equal') \nplt.show() # Affiche le graphique\n\n# Histogramme\ndata[\"montant\"].hist(density=True)\n\n# Histogramme plus beau (bin optimal k=[1+log2(n)])\ndata[data.montant.abs() &lt; 100][\"montant\"].hist(density=True,bins=20)\n</code></pre></p> <p>evaluate</p> <pre><code>from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n\naccuracy_score(y_test, y_pred_test)\nprecision_score(y_test, y_pred_test)\n\n\n(VN, FP), (FN, VP) = confusion_matrix(y_test, y_pred_test_logr)\n\npd.crosstab(df['col1'],df['col5'])              # display table with frequency of modality\npd.crosstab(df['col1'],df['col5'],normalize=1)  # display by percentage in the column direction\n</code></pre>"},{"location":"python/python/#scipy","title":"scipy","text":""},{"location":"python/python/#1-2-3from-scipystats-import-pearsonr-pearsonrdfbackers-dfpledged-coefficient-de-pearson-2-quantitative-values","title":"<pre><code>from scipy.stats import pearsonr\n\npearsonr(df['backers'], df['pledged'])          # coefficient de pearson (2 quantitative values)\n</code></pre>","text":""},{"location":"python/python/#geopandas","title":"geopandas","text":"<pre><code>import geopandas as pd\nimport contextly as ctx  # retrieves tile maps from the internet as basemaps for matplotlib \n\nctx.add_basemap(ax, crs = meuse.crs.to_string())\n</code></pre>"},{"location":"python/python/#folium","title":"folium","text":"<pre><code>import folium\nmap_osm = folium.Map(location=[location.latitude, location.longitude])\n\nfor ind, geo, com in df[['geometry', '1_f_commune']].itertuples():\n    map_osm.add_child(folium.RegularPolygonMarker(location=[geo.y,geo.x], popup=com,\n                       fill_color='#132b5e', radius=5))\n\nmap_osm\n</code></pre>"},{"location":"python/python/#geopy","title":"geopy","text":""},{"location":"python/python/#1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16from-geopygeocoders-import-nominatim-initialize-nominatim-api-geolocator-nominatimuser_agentmyapp-city-as-input-location-geolocatorgeocodenancy-printthe-latitude-of-the-location-is-locationlatitude-printthe-longitude-of-the-location-is-locationlongitude-latitude-longitude-as-input-coordinates-173850-784867-location-geolocatorreversecoordinates-city-addressgetcity-state-addressgetstate-country-addressgetcountry","title":"<pre><code>from geopy.geocoders import Nominatim\n\n# Initialize Nominatim API\ngeolocator = Nominatim(user_agent=\"MyApp\")\n\n# City as Input\nlocation = geolocator.geocode(\"Nancy\")\nprint(\"The latitude of the location is: \", location.latitude)\nprint(\"The longitude of the location is: \", location.longitude)\n\n# Latitude &amp; Longitude as Input\ncoordinates = \"17.3850 , 78.4867\"\nlocation = geolocator.reverse(coordinates)\ncity = address.get('city', '')\nstate = address.get('state', '')\ncountry = address.get('country', '')\n</code></pre>","text":""},{"location":"python/python/#time","title":"time","text":"<pre><code>import time\n\ntime.time()                                     # Return the time in seconds since the epoch as a floating point number \n                                                # Epoch time on Windows and most Unix : January 1, 1970, 00:00:00 (UTC) \n\ntime.strftime('%X')                             # displays 17:13:52\ntime.sleep(5)                                   # sleep for 5 sec\ntime.ctime()                                    # take time in seconds and return 'Sun Jun 20 23:21:05 1993'\ntime.gmtime(1561541)                            # Convert a time expressed in seconds since the epoch to a struct_time in UTC\n</code></pre>"},{"location":"python/python/#datetime","title":"datetime","text":"<p>formats %d Day of the month as a zero-padded decimal number.    01, 02, \u2026, 31 %b Month as locale\u2019s abbreviated name.                  Jan, Feb, \u2026, Dec (en_US); %m Month as a zero-padded decimal number.               01, 02, \u2026, 12 %y Year without century as a zero-padded decimal.       00, 01, \u2026, 99 %Y Year with century as a zero-padded decimal.          2012, 2013, \u2026, 9999 %H Hour (24-hour clock) as a zero-padded decimal.       00, 01, \u2026, 23 %M Minute as a zero-padded decimal number.              00, 01, \u2026, 59 %S Second as a zero-padded decimal number.              00, 01, \u2026, 59 %W Week number of the year (Monday as the first DoW)    00, 01, ..., 53</p> <pre><code>from datetime import datetime, timedelta\n\ndatetime.now()                                  # current date and time\ndatetime.today()                                # today date\n\nday=datetime.now().strftime(\"%d\")               # 19\nmonth=str(datetime.now().strftime(\"%b\"))        # Oct\nyear=datetime.now().strftime(\"%y\")              # 22\n\nend_date = datetime.now() + timedelta(days=7)\n\ndate_minus_2d = (datetime.now() - timedelta(days=2)) \\      # renvoi string ajd - 2jrs format\u00e9\n        .strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n</code></pre>"},{"location":"python/python/#matplotlib","title":"Matplotlib","text":"<pre><code>%matplotlib inline                              # magic function for IPython to choose graphical library (inline = Notebook internal library)\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()                              # figure container (axes, labels, data, etc..)\nax = plt.axes()                                 # grid above figure\nx = np.linspace(0, 10, 1000)\nax.plot(x, np.sin(x));\nplt.figure(figsize= (h, l))                     # resize figure\n\nfig, axes = plt.subplots(nrows=1,\n                         ncols=2, \n                         figsize=(16, 8)) # display multiple subplots at once \n\n\nplt.plot(t,t,'hy')\nplt.plot(t,t**2,'g-', linewidth=5)\nplt.plot(t,t**3,'b', marker='D')\nplt.xlim([0,50])\nplt.ylim([0,50])\nplt.xlabel('Abscisses')\nplt.ylabel('Ordonnees')\nplt.title(\"Un exemple de graphe\")               # graph title\nplt.axis([-1, 11, -1.5, 1.5]);                  # axis limit x(min,max) and y(min,max)\ndf = pd.read_csv('sales_data.csv')\nplt.plot(df['Month'],df['Product1'])\ndf.plot(x='Month', y='Prod1', title = \"Ventes\")\ndf.plot(x = 'Month', y = ['Product1','Product2'], style = [\"m--\", \"c:.\"], title = \"Ventes par mois\");\n\n#############\n# graph types\nplt.plot(x, np.sin(x - 0),                      # x and y (function)\n        color='blue',                           # color (can be : 'blue', 'g', '0.75', '#FF0000')\n        linestyle='solid',                      # linestyle ('solid','dashed', 'dashdot', 'dotted')\n        label='bleu')                           # legend\nplt.bar(x,y,width=1,edgecolor=\"white\")          # bar plot\nplt.step(x,y)                                   # step plot\nplt.scatter(x,y)                                # scatter plot\nplt.errorbar(x, y, yerr=dy, fmt='.k')           # when discrete value, plot error of value (often standard deviation)\nplt.show()                                      # Display graph\n\n###########\n# bar plots\nplt.bar(range(4), [2, 3, 4, 5] , color = 'green', width = 0.6)\nplt.bar(x, y2, bottom = y1)                     # superpose les barres\nplt.xticks([1,2,3], ['un', 'deux', 'trois'])    # replace 1,2,3 by 'un'... on abscisses axis\ndf.plot.bar(x = 'Month', y=['Product1', 'Product2', 'Returns'],stacked=True,rot=0)\n\n###############\n# scatter plots\nplt.scatter(range(0,7), [8,7,6,5,6,7,8], color='red', marker= '*', s=40)\n\n###########\n# histogram\nplt.hist([0,1,1, 2, 2, 2, 3, 4, 4, 4, 4, 4, 5, 5], range=(0, 6), bins = 6)\nplt.hist([0,8,10,13,15,16,16,18,32,36,39,40,43,45,48,49], bins = [0,10,20,40,50])\nplt.hist(x, range = (1, 6), \n            bins = 5, \n            color = '#EE3459',\n            density = True,\n            orientation = 'horizontal', \n            rwidth = 0.6)\nplt.hist([df.Product1, df.Product2], \n            bins = 6, color = ['#f27750', '#f7bf59'],\n            label = ['Product1', 'Product2'],\n            histtype = 'barstacked')           \n\ndf.plot.hist(y=['Product1', 'Product2'], bins = 7, rwidth = 0.8 , color= ['#0c4c83', '#830c4c'], alpha=0.5);\ndf.plot.hist(y=['Product1', 'Product2'], bins = 7, subplots=True, rwidth = 0.8 , color= ['#0c4c83', '#830c4c'], alpha=0.5);\ndf.hist(column=['Product1', 'Product2'], bins = 7, rwidth = 0.8 , color= ['#0c4c83']);\n\n###########\n# box plots\nplt.boxplot([[1, 2, 3, 4, 5], [7, 5, 8, 4, 9, 5, 7]])\n\n\ndf['Mois']= df.Month.apply(lambda x : x[3:])\nl=list()\nfor i in df.Mois.unique():\n    l.append(df[df['Mois'] == i]['Turnover'])\nplt.boxplot(l)\nplt.xticks(range(1,13),df.Mois.unique())\nplt.show()\n\n\ndf.boxplot(column= 'Turnover', by='Mois', figsize= (7,7));   \n\n############ \n# Pie Charts       \nplt.pie(x, labels = ['A', 'B', 'C', 'D', 'E'])\n\nplt.pie(x = df.head(6).Turnover, \n           labels = ['Janv', 'Fev', 'Mars'],\n           colors = ['red', 'orange', 'yellow'],\n           explode = [0, 0, 0.2],                       # extract on part\n           autopct = lambda x: str(round(x, 2)) + '%',  # format percentage\n           pctdistance = 0.7, labeldistance = 1.2,      # distance from center to display percentage\n           shadow = True)                               # with shadow or not\n\n\n# subplots\nplt.subplot(221)\nplt.bar(range(len(df)), df.Product1, label = 'Product1')\nplt.legend()\n\nplt.subplot(222)\nplt.scatter(df.Product1, df.Product2, c = 'm', label = \"Product2\")\nplt.legend()\n\ndf.plot(y = ['Product1', 'Product2', 'Returns', 'Turnover'], subplots=True, layout= (2,2),\n        style = ['b--', 'm:p', 'g-.', 'c-d'], figsize=(7,7));\n\nplt.figure(figsize = (7,7))\nplt.boxplot(df.Turnover)\nplt.title( 'Boxplot')\nplt.axes([0.65, 0.65, 0.2, 0.15], facecolor='#ffe5c1')\nplt.hist(df.Turnover, color='#FFC575')\nplt.xlabel('Distribution')\nplt.xticks([])\nplt.yticks([]);\n\n################\n# figure et axes\nfig = plt.figure(figsize=(8,4))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\nax1.plot([0, 2, 3], [1, 3, 2], 'green');\nax2.hist( [1, 2, 2, 2, 3, 3, 4, 5, 5]);\n\nt = ax.set_title('random numbers')\n\nax3 = fig.add_subplot(223, sharex=ax1)\nax4 = fig.add_subplot(224, sharex=ax2)\n\nfig,axes = plt.subplots(3,2,sharex=True,sharey=True)\nfor i in range(2):\n    for j in range(2):\n        axes[i,j].hist(np.random.randn(500), bins=50, color='black', alpha=0.5)\n\nax1.plot(s1,color='#33CCFF',marker='o',linestyle='-.',label='courbe 1')\nax1.set_xlim([0,21])\nax1.set_ylim([-15,15])\n\nax1.set_xticks(range(0,21,2))\nax1.set_xticklabels([\"j +\" + str(l) for l in range(0,21,2)])\nax1.set_xlabel('Dur\u00e9e apr\u00e8s le jour j')\nax1.legend(loc='best')\n\nax1.plot_date(dates, val, linestyle='-');\n\n########\n# LateX\nax.text(0.1, 0.5, r\"$ f(x,y) = x^2 + 3 \\times \\cos(y) $\", fontsize=22)\nax.set_title('$\\sin(2\\pi x)\\exp(-x)$ et les deux asymptotes $\\pm\\exp(-x)$')\n\n###############\n# contour plots\n\nx , y = np.linspace(-1,1,200), np.linspace(-1,2,200)\nX, Y = np.meshgrid(x,y)\nZ = (1-X)**2+(Y-X**2)**2\ncs = plt.contour(X,Y,Z)\nplt.clabel(cs);\nplt.contourf(X,Y,Z,20)\nplt.colorbar()\n\n############\n# polar plot\ntheta = np.arange(0., 2., 1./180.)*np.pi \nr = np.abs(np.sin(5*theta) - 2.*np.cos(theta))\nplt.polar(theta, r)\nplt.rgrids(np.arange(0.2, 3.1, .7), angle=0)\nplt.thetagrids(np.arange(45, 360, 90) );\n\nax = plt.subplot(111, projection='polar')\n\n########\n# images\n\nheart = plt.imread('heartbeat.png') \nplt.imshow(heart);\n\n# ajouter une image \u00e0 un graphique\nimport pandas as pd\nhb=pd.read_csv('hb.csv', header=None)\nplt.figure(figsize=(8,6))\nplt.ylim([0,140])\nplt.xlim([-2,260])\nplt.plot(hb)\nplt.text(95,130,'Electrocardiogramme', style='italic')\nplt.imshow(heart, extent = [80,170,60,140]) ;\n</code></pre>"},{"location":"python/python/#dash-plotly","title":"dash plotly","text":"<p>When to use Graph Objects https://plotly.com/python/graph-objects/</p>"},{"location":"python/python/#sockets","title":"sockets","text":"<pre><code>accept()                                    # accepte une connexion, retourne un nouveau socket et une adresse client \nbind(addr)                                  # associe le socket \u00e0 une adresse locale\nclose()                                     # ferme le socket\nconnect(addr)                               # connecte le socket \u00e0 une adresse distante \nconnect_ex(addr)                            # connect, retourne un code erreur au lieu d'une exception\ndup()                                       # retourne un nouveau objet socket identique \u00e0 celui en cours\nfileno()                                    # retourne une description du fichier\ngetpeername()                               # retourne l'adresse distante\ngetsockname()                               # retourne l'adresse locale\ngetsockopt(level, optname[, buflen])        # retourne les options du socket\ngettimeout()                                # retourne le timeout ou none\nlisten(n)                                   # commence \u00e0 \u00e9couter les connexions entrantes\nmakefile([mode, [bufsize]])                 # retourne un fichier objet pour le socket\nrecv(buflen[, flags])                       # recoit des donn\u00e9es\nrecv_into(buffer[, nbytes[, flags]])        # recoit des donn\u00e9es (dans un buffer)\nrecvfrom(buflen[, flags])                   # re\u00e7oit des donn\u00e9es et l'adresse de l'envoyeur\nrecvfrom_into(buffer[,nbytes,[,flags])      # re\u00e7oit des donn\u00e9es et l'adresse de l'envoyeur (dans un buffer)\nsendall(data[, flags])                      # envoye toutes les donn\u00e9es\nsend(data[, flags])                         # envoye des donn\u00e9es mais il se peut que pas toutes le soit\nsendto(data[, flags], addr)                 # envoye des donn\u00e9es \u00e0 une adresse donn\u00e9e\nsetblocking(0 | 1)                          # active ou d\u00e9sactive le blocage le flag I/O\nsetsockopt(level, optname, value)           # d\u00e9finit les options du socket\nsettimeout(None | float)                    # active ou d\u00e9sactive le timeout\nshutdown(how)                               # fermer les connexions dans un ou les deux sens.\n</code></pre>"},{"location":"python/python/#requests","title":"requests","text":"<pre><code>import requests\nr = requests.get('https://api.github.com/events')\nr = requests.post('https://httpbin.org/post', data={'key': 'value'})\nr = requests.put('https://httpbin.org/put', data={'key': 'value'})\nr = requests.delete('https://httpbin.org/delete')\nr = requests.head('https://httpbin.org/get')\nr = requests.options('https://httpbin.org/get')\n\nurl = \"https://...\"\nresponse = requests.request(\"GET\", url, headers=headers, data=payload)\nresponse.json()['key1']['key2']\n</code></pre>"},{"location":"python/python/#other-librairies","title":"other librairies","text":"<pre><code>matplotlib                          # plot graphs\nstatistics                          # deep into statistics \nsklearn                             # machine learning\nBeautiful Soup                      # Web Scraping static\nSelenium                            # Web Scraping dynamic\ncsv                                 # work with CSV files\nre                                  # regex manipulation      \nmath                                # all math functions (cosinus,sinus,exp,etc.)\nsys                                 # sytem functions\nos                                  # OS functions\ncalendar                            # calendar functions\nprofile                             # analyse function execution\nurllib2                             # get internet informations\ncv2                                 # computer vision\n</code></pre>"},{"location":"python/python/#how-to-use-a-library","title":"How to use a library","text":"<pre><code>import random as rd\nfrom randam import choices as ch\n</code></pre>"},{"location":"python/python/#domain-specific","title":"DOMAIN SPECIFIC","text":""},{"location":"python/python/#web-scraping","title":"WEB SCRAPING","text":""},{"location":"python/python/#beautifulsoup","title":"BeautifulSoup","text":"<p>methods <pre><code>pip install beautifulsoup4\nfrom bs4 import BeautifulSoup\n\n# beautifulsoup\nsoup.title                                              # &lt;title&gt;The Dormouse's story&lt;/title&gt;\nsoup.title.name                                         # u'title'\nsoup.title.string                                       # u'The Dormouse's story'\nsoup.p                                                  # &lt;p class=\"title\"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;\nsoup.p['class']                                         # u'title'\nsoup.title.parent.name                                  # u'head'\nsoup.head.contents                                      # # [&lt;title&gt;The Dormouse's story&lt;/title&gt;]\nsoup.prettify                                           # align text\nsoup.get_text()                                         # get all the text in the page\nsoup.find_all('a')                                      # find all &lt;a&gt; element in the page\nsoup.find(id=\"link3\")\nsoup.select(\"title\")                                    # find tags\nsoup.select(\"body a\")                                   # Find tags beneath other tags (a beneath body)\nsoup.select(\"head &gt; title\")                             # Find tags directly beneath other tags\nsoup.select(\"p &gt; a\")                                    # \nsoup.select(\"#link1 ~ .sister\")                         # Find siblings tags\nsoup.select(\".sister\")                                  # Find tags by CSS class\nsoup.select(\"[class~=sister]\")                          #\nsoup.select(\"#link1\")                                   # Find tags by ID\nsoup.select(\"#link1,#link2\")                            # Find tags that match any selector from a list of selectors\nsoup.select('a[href=\"http://example.com/elsie\"]')       # Find tags by value\n\n# selenium\n# for Colab\n!pip install selenium\n!apt-get update # to update ubuntu to correctly run apt install\n!apt install chromium-chromedriver\n!cp /usr/lib/chromium-browser/chromedriver /usr/bin\nimport sys\nsys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\nfrom selenium import webdriver\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument('--headless')\nchrome_options.add_argument('--no-sandbox')\nchrome_options.add_argument('--disable-dev-shm-usage')\nwd = webdriver.Chrome('chromedriver',options=chrome_options)\nwd.get(\"https://www.webite-url.com\")\n\n# googlesearch\npip install googlesearch                                # pip installation\nconda install -c conda-forge googlesearch               # conda installation\nsearch(requ\u00eate,                                         # (str) la requ\u00eate que vous voulez ex\u00e9cuter \n       tld='com',                                       # (str) le domaine\n       lang='en',                                       # (str) le langage\n       tbs='o',                                         # (str) Time limits (i.e \u201cqdr:h\u201d =&gt; last hour, \u201cqdr:d\u201d =&gt; last 24 hours, \u201cqdr:m\u201d =&gt; last month).\n       num=10,                                          # (int) nombre de r\u00e9sultat par page\n       start=0,                                         # (int) premier r\u00e9sultat \u00e0 r\u00e9cup\u00e9rer\n       stop=None,                                       # (int) dernier resultat \u00e0 r\u00e9cup\u00e9rer. (None = forever)\n       pause=2.0,                                       # (float) delai entre les demandes HTTP\n      ):\nlucky(*args, **kwargs)                                  # Shortcut to single-item search. Same arguments as the main search function, but the return value changes. \nget_tbs(from_date, to_date)                             # Helper function to format the tbs parameter\n\n\n# NewsPaper\npip install newspaper3k                                 # pip installation\nfrom newspaper import Article\narticle = Article(url)\narticle.download()\narticle.parse()\narticle.text\n\n# nltk\npip install nltk                                        # pip installation\nnltk.download('punkt')                                  # installation package punkt\narticle.nlp()                                           # make NLP work on 'article'\narticle.authors                                         # return name of authors\narticle.publish_date                                    # return published date\narticle.summary                                         # return summary\narticle.keywords                                        # return keywords\narticle.top_image                                       # return top image\narticle.movies                                          # return \n</code></pre></p> <p>interpreter example <pre><code>pip install beautifulsoup4\n\n# R\u00e9cup\u00e9ration du titre de la page HTML\n&gt;&gt; soup.title\n&lt;title&gt;&lt;Les chiens les plus mignons&gt;&lt;/title&gt;\n\n# R\u00e9cup\u00e9ration de la cha\u00eene de caract\u00e8res du titre HTML\n&gt;&gt; soup.title.string\n\"Les chiens les plus mignons\"\n\n# Trouver tous les \u00e9l\u00e9ments avec la balise &lt;a&gt;\n&gt;&gt; soup.find_all('a')\n[ &lt;a href=\"http://exemple.com/labradoodle\" class=\"race\" id=\"lien1\"&gt;LabraDoodle&lt;/a&gt;,\n&lt;a href=\"http://exemple.com/retriever\" class=\"race\" id=\"lien2\"&gt;Golden Retriever&lt;/a&gt;,\n&lt;a href=\"http://exemple.com/carlin\" class=\"race\" id=\"lien3\"&gt;Carlin&lt;/a&gt;]\n\n# Trouver les \u00e9l\u00e9ments avec l\u2019id du \u00ab lien1 \u00bb\n&gt;&gt; soup.find(id=\"lien1\")\n&lt;a href=\"http://exemple.com/labradoodle\" class=\"race\" id=\"lien1\"&gt;LabraDoodle&lt;/a&gt;\n\n#Trouver tous les \u00e9l\u00e9ments p avec la classe \u00ab title \u00bb\n&gt;&gt; soup.find_all(\"p\", class_=\"title\")\n\"Les meilleures races de chiens\"\n</code></pre></p> <p>script example <pre><code># 1\nimport requests\nfrom bs4 import BeautifulSoup\nurl = \"https://www.gov.uk/search/news-and-communications\"\npage = requests.get(url)\nsoup = BeautifulSoup(page.content, 'html.parser')\n\n# 2\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\npage_SC = urlopen(\"https://www.gov.uk/search/news-and-communications\")\nsoup = BeautifulSoup(page_SC, 'html.parser')\n\n# 3\nfrom bs4 import BeautifulSoup\nfrom urllib.request import Request, urlopen\nheaders = {'User-Agent': 'Mozilla/5.0'}\nurl = 'https://www.nationsonline.org/oneworld/IATA_Codes/IATA_Code_A.htm'\nresponse = Request(url, headers = headers)\npage = urlopen(response)\nsoup = BeautifulSoup(page, 'html.parser')\n\ntitres = soup.find_all(\"a\", classstrip_=\"gem-c-document-list__item-title\")\nfor title in titres:\n    print(title.string,\"\\n\")\n\n# trouve le nom aux balises &lt;a&gt; et classes 'elco-anchor'\nnoms_SC = soup.findAll(name = 'a', attrs = {'class': 'elco-anchor'})\n\n\n\n# Ouvrir fichier avec le package CSV\nimport csv\n\nwith open('couleurs_preferees.csv') as fichier_csv:\n   reader = csv.DictReader(fichier_csv, delimiter=',')\n   for ligne in reader:\n      print(ligne['nom'] + \" travaille en tant que \" + ligne['metier'] + \n      \" et sa couleur pr\u00e9f\u00e9r\u00e9e est \" + ligne['couleur_preferee'])\n      `\n</code></pre></p>"},{"location":"python/python/#data-cleaning","title":"DATA CLEANING","text":"<p>purpose - have a clean dataset to manipulate - manage missing values (NaN)</p> <p>3 categories of transformation - manage duplicates (duplicated, drop_duplicates) - modify elements (replace, rename, astype) - operations on DF values (apply, lambda)</p>"},{"location":"python/python/#duplicates","title":"duplicates","text":"<pre><code>df.duplicated()\ndf.duplicated().sum()\ndf.loc[df[['col1','col2']].duplicated(keep=False),:].sum()      # select all duplicates on columns col1 and col2\ndf.drop_duplicates(subset=None, keep=first, inplace=False)      # be carful with inplace. let False by default\n</code></pre>"},{"location":"python/python/#replacing","title":"replacing","text":"<pre><code>df.replace(to_replace, value, ...)\n\n# column renaming\ndictionnaire = {'ancien_nom1': 'nouveau_nom1',\n                'ancien_nom2': 'nouveau_nom2'}\ndf = df.rename(dictionnaire, axis = 1)\n\n# change column type \n# M\u00e9thode 1 : \ndictionnaire = {'col_1': 'int',\n                'col_2': 'float'}\ndf = df.astype(dictionnaire)\n# M\u00e9thode 2 : \ndf['col_1'] = df['col_1'].astype('int')\n</code></pre>"},{"location":"python/python/#operations-on-values","title":"operations on values","text":"<p>apply df.apply(func, axis, ...) <pre><code># define a function\ndef get_day(d):\n    return d.split('-')[0]\n# apply function to column \ndays = transactions['tran_date'].apply(get_day)\n# create a new column\ntransactions['day'] = days\n</code></pre></p> <p>lambda in combination with apply <pre><code># normal function\ndef increment(x): \n   return x+1\n# with lambda  \nincrement = lambda x: x+1\n\n# combining lambda and apply\ntransactions['day'] = transactions['tran_date'].apply(lambda date: date.split('-')[0])\ntransactions['prod_cat'] = transactions.astype('str').apply(lambda row: row['prod_cat_code']+'-'+row['prod_subcat_code'],\n                                                            axis = 1)\n</code></pre></p>"},{"location":"python/python/#missing-values","title":"missing values","text":"<ul> <li>detection (isna,any)</li> <li>replacement (fillna)</li> <li>remove (dropna)</li> </ul> <p>detection <pre><code>df.isna()                                   # return a df with True or false for each value\ndf.isna().any(axis = 0)                     # columns with at least 1 NaN\ndf.isna().any(axis = 1)                     # rows with at least 1 NaN\ndf[df.isna().any(axis = 1)]                 # conditionnal indexing to return only rows with NaN\ndf.isnull().sum(axis = 0)                   # number of NaN by column\n</code></pre></p> <p>replacement - variable of numerical type are often replaced with      - mean     - median     - min/max - variable of categorical type are often replaced with      - mode     - arbitrary constante (0, -1)</p> <p>Be careful to select the right column to replace NaN</p> <p>fillna</p> <pre><code>df.fillna(0)                                # replace NaN with 0\ndf.fillna(df.mean())                        # replace NaN with column mean (could be median, min,max...)\n\n# On remplace les NANs de 'prod_subcat_code' par -1\ntransactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1)\n\n# On d\u00e9termine le mode de 'store_type'\nstore_type_mode = transactions['store_type'].mode()\n\n# On remplace les NANs de 'store_type' par son mode\ntransactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n\n# On v\u00e9rifie que ces deux colonnes ne contiennent plus de NANs\ntransactions[['prod_subcat_code', 'store_type']].isna().sum()\n\n# voir les NaN d'une colonne\ncustomer.loc[customer['city_code'].isnull(),:]\n</code></pre> <p>dropna removes rows or columns dropna(axis, how, subset, ..) - axis : 0 remove rows or 1 remove columns - how : 'any' at least 1 NaN or 'all' all NaN - subset : indicates rows/columns in which we search for NaN</p> <pre><code>df = df.dropna(axis = 0, how = 'any')\ndf = df.dropna(axis = 1, how = 'all')\ndf = df.dropna(axis = 0, how = 'all', subset = ['col2','col3','col4'])\n</code></pre>"},{"location":"python/python/#data-processing","title":"DATA PROCESSING","text":"<p>filter, merge, sort et group</p>"},{"location":"python/python/#filter-indexation-conditionnelle","title":"Filter (indexation conditionnelle)","text":"<ul> <li>'et' : &amp;</li> <li>'ou' : |</li> <li>'non' : -</li> </ul> <pre><code># &amp;\nprint(df[(df['annee'] == 1979) &amp; (df['surface'] &gt; 60)])\n# |\nprint(df[(df['ann\u00e9e'] &gt; 1900) | (df['quartier'] == 'P\u00e8re-Lachaise')])\n# -\nprint(df[-(df['quartier'] == 'Bercy')])\n</code></pre>"},{"location":"python/python/#merge-df-with-concat-and-merge","title":"Merge df with concat and merge","text":""},{"location":"python/python/#concat","title":"concat","text":"<p>pandas.concat(objs, axis..) - obj : list of df - axis : 0 (verticaly) ou 1 (horizontally)</p> <p>if dimensions don't match, fill with NaN <pre><code>part_1 = transactions[transactions.columns[:4]]\npart_2 = transactions[transactions.columns[4:]]\nunion = pd.concat([part_1,part_2], axis = 1)\n</code></pre></p>"},{"location":"python/python/#merge","title":"merge","text":"<p>2 df can be merge if 1 column in common merge(right, on, how, ...) - right : df to merge on the right with the one calling merge - on : shared column - how : joint (based on SQL)     - 'inner': Default. Not recommended because of data loss but no NaN     - 'outer': Keep all data but generate lot of NaN     - 'left' : all left data but only the right that match. Data loss and generate NaN     - 'right': all right data but only the left that match. Data loss and generate NaN</p> <p>make a outer/right/left joint with dropna(how = 'any') is equivalent to inner joint</p> <p>pay attention to index column that can change or be removed.</p> <pre><code># example\nPersonnes.merge(right = Vehicule, on = 'Voiture', how = 'right')\n\n# set new index for df with column name\ndf = df.set_index('Nom')\n\n# new index from numpy array or pandas series\nnew_index = ['10000' + str(i) for i in range(6)]\nindex_array = np.array(new_index)\nindex_series = pd.Series(new_index)\ndf = df.set_index(new_index)\ndf = df.set_index(index_array)\ndf = df.set_index(index_series)\n\n# reset default index\ndf = df.reset_index()\n\n# get index of df\ndf.index\n</code></pre>"},{"location":"python/python/#sort","title":"Sort","text":"<p>sort_values(by, ascending,...) - by : column to sort - ascending : (True or False) True by default</p> <pre><code>df_sorted = df.sort_values(by = 'Points_bonus', ascending = True)\ndf_sorted = df.sort_values(by = ['Points_bonus', 'Note'], ascending = True)\n</code></pre> <p>sort_index() often combined with set_index()</p> <pre><code># On d\u00e9finit la colonne 'Note' comme l'index de df\ndf = df.set_index('Note')\n# On trie le DataFrame df selon son index\ndf = df.sort_index()\n</code></pre>"},{"location":"python/python/#group-agg","title":"group, agg","text":"<p>groupby : return a DataFrameGroupBy operations: - split data - apply function - combine results</p> <p>agg : aggregate data - dictionary :     - key : column name     - value : function to apply</p> <pre><code>functions_to_apply = {\n    # Les m\u00e9thodes statistiques classiques peuvent \u00eatre renseign\u00e9es avec\n    # chaines de caract\u00e8res\n    'total_amt' : ['min', 'max', 'sum'],\n    'store_type' : n_modalities\n    }  \n\ntransactions.groupby('cust_id').agg(functions_to_apply)\n\n# example\n# Quantit\u00e9 maximale\nmax_qty = lambda qty: qty[qty &gt; 0].max()\n# Quantit\u00e9 minimale\nmin_qty = lambda qty: qty[qty &gt; 0].min()\n# Quantit\u00e9 m\u00e9diane\nmedian_qty = lambda qty : qty[qty &gt; 0].median()\n# D\u00e9finition du dictionnaire de fonctions \u00e0 appliquer\nfunctions_to_apply = {\n    'qty' : [max_qty, min_qty, median_qty]\n}\n# Operation groupby\nqty_groupby = transactions.groupby('cust_id').agg(functions_to_apply)\n# Pour un meilleur affichage, on peut renommer les colonnes produite par le groupby\nqty_groupby.columns.set_levels(['max_qty', 'min_qty', 'median_qty'], level=1, inplace = True)\n</code></pre>"},{"location":"python/python/#crosstab","title":"crosstab","text":"<p>frequency of modality pairs  crosstab(colonne1, colonne2, normalize = 1) - normalize : display percentage  (0:rows, 1:columns) </p> <pre><code>colonne1 = transactions['prod_cat_code']\ncolonne2 = transactions['prod_subcat_code']\npd.crosstab(colonne1, colonne2)\n</code></pre>"},{"location":"python/python/#eda","title":"EDA","text":"<pre><code># select country not in subset of valid countries to replace by NaN values\nVALID_COUNTRIES = ['France', 'C\u00f4te d\\'ivoire', 'Madagascar']\nmask = ~data['pays'].isin(VALID_COUNTRIES)\ndata.loc[mask, 'pays'] = np.NaN\n</code></pre>"},{"location":"python/python/#machine-learning-regression","title":"MACHINE LEARNING : Regression","text":""},{"location":"python/python/#regression-lineaire-univariee","title":"*R\u00e9gression Lin\u00e9aire Univari\u00e9e*","text":"<p>y\u2248\u03b21x+\u03b20</p> <p>y = target x = feature \u03b2 = param\u00e8tre</p>"},{"location":"python/python/#regression-lineaire-multiple","title":"*R\u00e9gression Lin\u00e9aire Multiple*","text":"<p>y\u2248 \u03b20 + \u03b21x1 + \u03b22x2 + \u22ef + \u03b2pxp</p> <p>\u2248 \u03b20 + \u2211j=1p \u03b2jxj</p>"},{"location":"python/python/#probleme","title":"Probl\u00e8me","text":"<p>trouver les meilleurs \u03b2 qui minimise l\u2019erreur entre le mod\u00e8le et les vraies valeurs</p>"},{"location":"python/python/#scikit-learn","title":"scikit-learn","text":"<p>pour r\u00e9soudre les probl\u00e8mes de machine learning</p>"},{"location":"python/python/#etapes-a-la-base-de-toute-resolution-dun-probleme-de-machine-learning","title":"\u00c9tapes\u00a0\u00e0 la base de toute r\u00e9solution d'un probl\u00e8me de Machine Learning :","text":"<ul> <li>On pr\u00e9pare les donn\u00e9es en s\u00e9parant les variables\u00a0explicatives\u00a0de la variable\u00a0cible.</li> <li>On\u00a0s\u00e9pare\u00a0le jeu de donn\u00e9es en deux (un jeu d'entra\u00eenement\u00a0et un jeu de\u00a0test) \u00e0 l'aide de la fonction\u00a0<code>train_test_split</code>\u00a0du sous-module\u00a0<code>sklearn.model_selection</code>.</li> <li>On\u00a0instancie\u00a0un mod\u00e8le comme\u00a0<code>LinearRegression</code>\u00a0ou\u00a0<code>GradientBoostingRegressor</code>\u00a0gr\u00e2ce au constructeur de la classe.</li> <li>On\u00a0entra\u00eene\u00a0le mod\u00e8le sur le jeu de donn\u00e9es d'entra\u00eenement \u00e0 l'aide de la m\u00e9thode\u00a0<code>fit</code>.</li> <li>On effectue une\u00a0pr\u00e9diction\u00a0sur les donn\u00e9es de test gr\u00e2ce \u00e0 la m\u00e9thode\u00a0<code>predict</code>.</li> <li>On\u00a0\u00e9value les performances\u00a0de notre mod\u00e8le en calculant l'erreur entre ces pr\u00e9dictions et les v\u00e9ritables valeurs de la variable cible des donn\u00e9es de\u00a0test.</li> </ul>"},{"location":"python/python/#separation-colonnes-features-et-target","title":"Separation colonnes features et target","text":"<pre><code>X = df[df.columns[:15]]\ny = df[df.columns[15:]]\n\nou\n\n# Variables explicatives\nX = df.drop(['price'], axis = 1)\n# Variable cible\ny = df['price']\n</code></pre>"},{"location":"python/python/#separate-dataset-between-train-and-test-dataset","title":"Separate dataset between train and test dataset","text":"<ul> <li>train: find the best \u03b2</li> <li> <p>test : test the trained model to study his capacity to generalize predictions on data never seen befor</p> </li> </ul>"},{"location":"python/python/#train_test_split","title":"train_test_split","text":"<p>train_test_split(arrays,\u00a0test_size=None,\u00a0train_size=None,\u00a0random_state=None,\u00a0shuffle=True,\u00a0stratify=None)</p> <p>https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html</p> <pre><code>from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)\n</code></pre> <p>test_size : proportion of test dataset</p> <p>random_state : </p> <ul> <li>\u2018None\u2019 for different results for multiple calls.</li> <li>Int for repeatible results</li> </ul>"},{"location":"python/python/#create-a-regression-model","title":"Create a regression model","text":"<pre><code>from sklearn.linear_model import LinearRegression\n</code></pre> <p>All model class have 2 methods to train and evaluate model:</p> <ul> <li>fit : train model</li> <li>predict : predict results from features</li> </ul> <pre><code># Instantiation du mod\u00e8le\nlr = LinearRegression()\n\n# Entra\u00eenement du mod\u00e8le\nlr.fit(X_train, y_train)\n\n# Pr\u00e9diction de la variable cible pour le jeu de donn\u00e9es TRAIN\ny_pred_train = lr.predict(X_train)\n\n# Pr\u00e9diction de la variable cible pour le jeu de donn\u00e9es TEST\ny_pred_test = lr.predict(X_test)\n</code></pre>"},{"location":"python/python/#evaluate-model","title":"Evaluate model","text":"<p>Mean Squared Error</p> <p>difficult to interpret</p> <pre><code>from sklearn.metrics import mean_squared_error\nmean_squared_error(y_true = y_test, y_pred = y_pred_test)\n</code></pre> <p>Mean Absolute Error</p> <p>same scale as target</p> <pre><code>from sklearn.metrics import mean_absolute_error\nmae_train = mean_absolute_error(y_train, y_pred_train)\n</code></pre>"},{"location":"python/python/#overfitting","title":"Overfitting","text":"<p>GradientBoost : learn well on train dataset but doesn\u2019t generalize well</p> <pre><code>gbr = GradientBoostingRegressor(n_estimators = 1000,\n                                max_depth = 10000,\n                                max_features = 15,\n                                validation_fraction = 0)\n# Fit\ngbr.fit(X_train, y_train)\n# Predict train\ny_pred_train_gbr = gbr.predict(X_train)\n# Predict test\ny_pred_test_gbr = gbr.predict(X_test)\n\n# MSE train\nmse_train_gbr = mean_squared_error(y_train, y_pred_train_gbr)\n# MSE test\nmse_test_gbr = mean_squared_error(y_test, y_pred_test_gbr)\n\n# MAE train\nmae_train_gbr = mean_absolute_error(y_train, y_pred_train_gbr)\n# MAE test\nmae_test_gbr = mean_absolute_error(y_test, y_pred_test_gbr)\n\nmean_price_gbr = df['price'].mean()\n\nprint(\"Relative error\", mae_test_gbr / mean_price_gbr)\n\n# Results #########################\n# MSE train gbr: 25799.588888888888\n# MSE test gbr: 2626919.693281389\n# MAE train gbr: 32.718518524427424\n# MAE test gbr: 1189.7782300506872\n# Relative error 0.10394953190531596\n</code></pre> <p>For regression with <code>LinearRegression</code>\u00a0we had :</p> <ul> <li>MAE train lr: 1680.4078748721086</li> <li>MAE test lr: 1773.9135394428085</li> </ul> <p>For regression with <code>GradientBoostingRegressor</code>\u00a0we have :</p> <ul> <li>MAE train gbr: 20.740740828767215</li> <li>MAE test gbr: 1442.6573741134125</li> </ul> <p>Mean absolute error for train dataset is too low compare to test dataset too high. That \u2018s why the performance of the model must be evaluated on test dataset.</p> <p><code>GradientBoostingRegressor</code>\u00a0is better than <code>LinearRegression</code>\u00a0though.</p>"},{"location":"python/python/#polynomiale-regression","title":"*Polynomiale Regression*","text":"<p>y = \u03b20 + \u03b21x + \u03b22x^2</p> <p>Order 2</p> <p>y \u2248 \u03b20 + \u03b21x1^2 + \u03b22x2^2+ \u03b23x3^2+ \u03b24x1x2+ \u03b25x2x3 + \u03b26x1x3</p> <p>When features grow or Order higher, it leads to overfitting</p> <pre><code>from sklearn.preprocessing import PolynomialFeatures\n\npoly_feature_extractor = PolynomialFeatures(degree = 2)\n\n# Application de la transformation sur X_train et X_test\nX_train_poly = poly_feature_extractor.fit_transform(X_train)\nX_test_poly = poly_feature_extractor.transform(X_test)\n</code></pre> <p>poly_feature_extractor is a <code>transformer</code> not a model:</p> <ul> <li>fit : does nothing</li> <li>transform : apply transformation to dataset</li> </ul> <p>these 2 methods can be replaced by fit_transform() directly</p> <pre><code># Instantiation d'un mod\u00e8le de r\u00e9gression lin\u00e9aire\npolyreg = LinearRegression()\n\n# Entra\u00eenement du mod\u00e8le sur les features polynomiaux\npolyreg.fit(X_train_poly, y_train)\n\n# Evaluation du mod\u00e8le sur les donn\u00e9es d'entra\u00eenement\ny_pred_train = polyreg.predict(X_train_poly)\nprint(\"MAE Train:\", mean_absolute_error(y_train, y_pred_train), '\\n')\n\n# Evaluation du mod\u00e8le sur les donn\u00e9es de test\ny_pred_test = polyreg.predict(X_test_poly)\nprint(\"MAE Test:\", mean_absolute_error(y_test, y_pred_test), '\\n')\n\nprint(\"Nous sommes absolument dans un r\u00e9gime de surapprentissage.\")\nprint(\"Le mod\u00e8le de r\u00e9gression polynomiale est performant sur les donn\u00e9es d'entrainement mais pas sur les donn\u00e9es de test.\")\nprint(\"Le mod\u00e8le de r\u00e9gression polynomiale d'ordre 3 est beaucoup moins performant que la r\u00e9gression lin\u00e9aire simple.\")\n</code></pre>"},{"location":"python/python/#machine-learning-classification","title":"MACHINE LEARNING : Classification","text":"<p>Regression : continuous values (numerical)</p> <p>Classification : discrete values (numerical or litteral)</p> <p>ex:</p> <p></p> <p>Scikit-learn propose de nombreux mod\u00e8les de classification que l'on peut regrouper en deux familles :</p> <ul> <li>Les mod\u00e8les\u00a0lin\u00e9aires\u00a0comme\u00a0<code>**LogisticRegression**</code>.</li> <li>Les mod\u00e8les\u00a0non-lin\u00e9aires\u00a0comme\u00a0<code>KNeighborsClassifier</code>.</li> </ul> <p>L'utilisation de ces mod\u00e8les se fait de la m\u00eame fa\u00e7on pour\u00a0tous\u00a0les mod\u00e8les de scikit-learn :</p> <ul> <li>Instanciation\u00a0du mod\u00e8le.</li> <li>Entra\u00eenement\u00a0du mod\u00e8le :\u00a0<code>model.fit(X_train, y_train)</code>.</li> <li>Pr\u00e9diction\u00a0:\u00a0<code>model.predict(X_test)</code>.</li> </ul> <p>La pr\u00e9diction sur le jeu de test nous permet d'\u00e9valuer\u00a0la performance du mod\u00e8le gr\u00e2ce \u00e0 des\u00a0m\u00e9triques\u00a0adapt\u00e9es.</p> <p>Les m\u00e9triques que nous avons vues s'utilisent pour la classification\u00a0binaire\u00a0et se calculent gr\u00e2ce \u00e0 4 valeurs :</p> <ul> <li>Vrais Positifs : Pr\u00e9diction =\u00a0+\u00a0| R\u00e9alit\u00e9 =\u00a0+</li> <li>Vrais N\u00e9gatifs : Pr\u00e9diction =\u00a0-\u00a0| R\u00e9alit\u00e9 =\u00a0-</li> <li>Faux Positifs : Pr\u00e9diction =\u00a0+\u00a0| R\u00e9alit\u00e9 =\u00a0-</li> <li>Faux N\u00e9gatifs : Pr\u00e9diction = -\u00a0\u00a0| R\u00e9alit\u00e9 =\u00a0+</li> </ul> <p>Toutes ces valeurs peuvent se calculer \u00e0 l'aide de la\u00a0matrice de confusion\u00a0g\u00e9n\u00e9r\u00e9e par la fonction\u00a0<code>confusion_matrix</code>\u00a0du sous-module\u00a0<code>**sklearn.metrics**</code>\u00a0ou par la fonction\u00a0<code>pd.crosstab</code>.</p> <p>Gr\u00e2ce \u00e0 ces valeurs, nous pouvons calculer des m\u00e9triques comme :</p> <ul> <li>L'accuracy\u00a0: La proportion d'observations correctement classifi\u00e9es.</li> <li>La\u00a0pr\u00e9cision\u00a0: La proportion de vrais positifs parmi toutes les pr\u00e9dictions positives du mod\u00e8le.</li> <li>Le\u00a0rappel\u00a0: La proportion d'observations r\u00e9ellement positives qui ont \u00e9t\u00e9 correctement classifi\u00e9es positives par le mod\u00e8le.</li> </ul> <p>Toutes ces m\u00e9triques peuvent s'obtenir \u00e0 l'aide de la fonction \u00a0<code>classification_report</code>\u00a0du sous-module\u00a0<code>sklearn.metrics</code>.</p> <p>Le\u00a0<code>F1-Score</code>\u00a0quantifie l'\u00e9quilibre\u00a0entre ces m\u00e9triques, ce qui nous donne un crit\u00e8re\u00a0fiable\u00a0pour\u00a0choisir\u00a0le mod\u00e8le le plus adapt\u00e9 \u00e0 notre probl\u00e8me.</p>"},{"location":"python/python/#linear-classification-k-nearest-neighbors","title":"Linear Classification *: K-Nearest Neighbors*","text":"<p>for K=5, if 5 neighbors are democrats, the observations will be classified as democrats</p> <pre><code>from sklearn.neighbors import KNeighborsClassifier\n\n# Instanciation du mod\u00e8le\nknn = KNeighborsClassifier(n_neighbors = 6)\n# Entra\u00eenement du mod\u00e8le sur le jeu d'entra\u00eenement\nknn.fit(X_train, y_train)\n# Pr\u00e9diction sur les donn\u00e9es de test\ny_pred_test_knn = knn.predict(X_test)\n# Affichage des 10 premi\u00e8res pr\u00e9dictions\nprint(y_pred_test_knn[:10])\n\n# Results ############################################################\n# array(['democrat', 'democrat', 'democrat', 'democrat', 'democrat',\n#       'democrat', 'democrat', 'democrat', 'republican', 'democrat'],\n#       dtype=object)\n</code></pre>"},{"location":"python/python/#linear-classification-logistic-regression","title":"Linear Classification *: Logistic Regression*","text":"<p>Probability that y = 0 or 1</p> <p></p> <p>f is called the <code>sigmo\u00efd function</code> or <code>logistic function</code> </p> <pre><code>from sklearn.linear_model import LogisticRegression\n\n# Instanciation du mod\u00e8le\nlogreg = LogisticRegression()\n# Entra\u00eenement du mod\u00e8le sur le jeu d'entra\u00eenement\nlogreg.fit(X_train, y_train)\n# Pr\u00e9diction sur les donn\u00e9es de test\ny_pred_test_logreg = logreg.predict(X_test)\n# Affichage des 10 premi\u00e8res pr\u00e9dictions\nprint(y_pred_test_logreg[:10])\n\n# Results ###########################################################\n# array(['democrat', 'republican', 'democrat', 'democrat', 'democrat',\n#       'democrat', 'democrat', 'democrat', 'republican', 'democrat'],\n#       dtype=object)\n</code></pre>"},{"location":"python/python/#evaluate-classification-model-performance","title":"Evaluate classification model performance","text":"<p>n : number of observations</p> <p>VP : vrai positif, FP : faux positif, VN : vrai n\u00e9gatif, FN : faux n\u00e9gatif</p> <p></p> <p>Different metrics:</p> <ul> <li> <p><code>accuracy</code> : [accuracy_score(y_test, y_pred)]</p> <p>true prediction ratio (most used) </p> <p>good indicator when VP and VN is well balanced</p> </li> </ul> <p>$$ \\mathrm{accuracy} = \\frac{\\mathrm{VP} + \\mathrm{VN}}{n} $$</p> <ul> <li> <p><code>precision</code>\u00a0: [precision_score(y_test, y_pred, pos_label)]</p> <p>true prediction among positive prediction</p> <p>good indicator when dominant class</p> </li> </ul> <p>$$ \\mathrm{precision} = \\frac{\\mathrm{VP}}{\\mathrm{VP} + \\mathrm{FP}} $$</p> <ul> <li> <p><code>recall</code> : [recall_score(y_test, y_pred, pos_label)]</p> <p>number of true positive classification among all positive</p> <p>good indicator when dominant class</p> </li> </ul> <p>$$ \\mathrm{recall} = \\frac{\\mathrm{VP}}{\\mathrm{VP} + \\mathrm{FN}} $$</p> <ul> <li> <p><code>confusion matrix</code> : calculate all 3 metrics.</p> <p>confusion_matrix(y_true, y_pred)</p> <p>pd.crosstab(y_test, y_pred_test_knn, rownames=['Realit\u00e9'], colnames=['Pr\u00e9diction'])</p> </li> </ul> <p>$$ \\mathrm{Confusion Matrix} = \\begin{bmatrix}                                     \\mathrm{VN} &amp; \\mathrm{FP} \\                                     \\mathrm{FN} &amp; \\mathrm{VP}                                 \\end{bmatrix} $$</p> <pre><code>from sklearn.metrics import confusion_matrix\n\n# Calcul et affichage de la matrice de confusion\nmatrice_confusion = confusion_matrix(y_test, y_pred_test_knn)\nprint(\"Matrice de Confusion:\\n\",  matrice_confusion)\n\nprint(\"\\nLe mod\u00e8le knn a fait\", matrice_confusion[0, 1], \"Faux Positifs.\")\n\n# Calcul de l'accuracy, precision et rappel\n(VN, FP), (FN, VP) = confusion_matrix(y_test, y_pred_test_knn)\nn = len(y_test)\n\nprint(\"\\nKNN Accuracy:\", (VP + VN) / n)\nprint(\"\\nKNN Pr\u00e9cision:\", VP / (VP + FP))\nprint(\"\\nKNN Rappel:\", VP / (VP + FN))\n\n# Results ##########################################################\n# Matrice de Confusion:\n# [[48  5]\n# [ 2 32]]\n\n# Le mod\u00e8le knn a fait 5 Faux Positifs.\n# KNN Accuracy: 0.9195402298850575\n# KNN Pr\u00e9cision: 0.8648648648648649\n# KNN Rappel: 0.9411764705882353\n</code></pre> <pre><code>from sklearn.metrics import accuracy_score, precision_score, recall_score\n\n# Calcul et affichage de la matrice de confusion\npd.crosstab(y_test, y_pred_test_logreg, rownames=['Realit\u00e9'], colnames=['Pr\u00e9diction'])\n\n# Calcul de l'accuracy, precision et rappel\nprint(\"\\nLogReg Accuracy:\", accuracy_score(y_test, y_pred_test_logreg))\nprint(\"\\nLogReg Pr\u00e9cision:\", precision_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\nprint(\"\\nLogReg Rappel:\", recall_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n\n# Results ###########################################################\n# LogReg Accuracy: 0.9310344827586207\n# LogReg Pr\u00e9cision: 0.8888888888888888\n# LogReg Rappel: 0.9411764705882353\n</code></pre> <pre><code>from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred_test_logreg))\nprint(classification_report(y_test, y_pred_test_knn))\n\n# Results ###########################################################\n#               precision    recall  f1-score   support\n\n#    democrat       0.96      0.92      0.94        53\n#  republican       0.89      0.94      0.91        34\n\n#    accuracy                           0.93        87\n#   macro avg       0.92      0.93      0.93        87\n#weighted avg       0.93      0.93      0.93        87\n\n#              precision    recall  f1-score   support\n\n#    democrat       0.96      0.91      0.93        53\n#  republican       0.86      0.94      0.90        34\n\n#    accuracy                           0.92        87\n#   macro avg       0.91      0.92      0.92        87\n#weighted avg       0.92      0.92      0.92        87\n</code></pre> <p><code>F1-Score</code> : for classification problem adequate. Kind of a mean of precision and recall</p> <pre><code>from sklearn.metrics import f1_score\n\nprint(f1_score(y_test, y_pred_test_knn, pos_label = 'republican'))\nprint(f1_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n\n# Results ###########################################################\n# F1 KNN: 0.9014084507042254\n# F1 LogReg: 0.9142857142857143\n</code></pre>"},{"location":"python/python/#sql-alchemy","title":"SQL ALCHEMY","text":"<pre><code>engine = create_engine('sqlite:///chinook.db', echo=True)\ninspector = inspect(engine)\ninspector.get_table_names()\ninspector.get_columns(table_name='col')\ninspector.get_foreign_keys(table_name='table')\nconn = engine.connect()\n\n# request\nstmt = text(\"SELECT Title FROM albums LIMIT 10;\")\nresult = conn.execute(stmt)\nresult.fetchall() \n\n# create a table\nuser = Table('user',metadata_obj,\n             Column('user_id', Integer, primary_key=True),\n             Column('user_name', String(16), nullable=False),\n             Column('email_address', String(60)),\n             Column('nickname', String(50), nullable=False)\n             ForeignKey(\"parent.id\")\n)\n# \nmetadata_obj.create_all(engine)\n\n# delete table\ndrop = text('DROP TABLE IF EXISTS name_table;')\nresult = engine2.execute(drop)\n</code></pre>"},{"location":"python/python/#pyspark","title":"PySpark","text":"<p>Imports <pre><code># Import PySpark related modules\nimport pyspark\nfrom pyspark.rdd import RDD\nfrom pyspark.sql import Row\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import functions\nfrom pyspark.sql.functions import (\n    lit, \n    desc, \n    col, \n    size, \n    array_contains,\n    isnan, \n    udf, \n    hour, \n    array_min, \n    array_max, \n    countDistinct\nfrom pyspark.sql.types import *\n</code></pre></p> <p>conf https://spark.apache.org/docs/latest/configuration.html <pre><code># Initialize a spark session.\nMAX_MEMORY = '15G'\nconf = pyspark.SparkConf().setMaster(\"local[*]\") \\\n        .set('spark.executor.heartbeatInterval', 10000) \\\n        .set('spark.network.timeout', 10000) \\\n        .set(\"spark.core.connection.ack.wait.timeout\", \"3600\") \\\n        .set(\"spark.executor.memory\", MAX_MEMORY) \\\n        .set(\"spark.driver.memory\", MAX_MEMORY)\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Pyspark guide\") \\\n    .config(conf=conf) \\\n    .getOrCreate()\n\n# Load the main data set into pyspark data frame \ndf = spark.read.json('file.json', mode=\"DROPMALFORMED\")\n</code></pre></p> <p>overview <pre><code>df.dtypes\ndf.describe(['col1','col2']).toPandas()             # if no col is given then describe all columns\ndf.limit(2).toPandas()\ndf.printSchema()                                    # print the schema of df\ndf.schema                                           # Returns the schema of this DataFrame as a pyspark.sql.types.StructType\n\ndf.collect()[:k]                                    # Lazy evaluation \ndf.first()                                          # Returns the first row as a Row.\ndf.head(n)                                          # Returns the first n rows as Rows.\ndf.show(n)                                          # Returns the first n rows as Rows.\ndf.take(n)                                          # Returns the first n rows as list of Rows.\ndf.count()                                          # Count the number of rows in df\ndf.distinct().count()                               # Count the number of distinct rows in df\n</code></pre></p>"},{"location":"python/python/#generator","title":"Generator","text":"<p>use cases - when dealing with a huge dataset - scenarios where we do NOT need to reiterate it more than once (can only be iterated once) - lazy evaluation - They are a great way to generate infinite sequences in a memory-efficient manner</p>"},{"location":"sql/basics/","title":"Basics","text":""},{"location":"sql/basics/#todo","title":"TODO","text":""}]}